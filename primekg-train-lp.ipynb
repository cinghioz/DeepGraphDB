{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6a94a4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from typing import Dict, Tuple\n",
    "from collections import defaultdict\n",
    "import time\n",
    "\n",
    "class PrimeKGLoader:\n",
    "    \"\"\"\n",
    "    Prepares PrimeKG data for efficient loading into DGL heterogeneous graphs.\n",
    "    Each node type gets sequential IDs starting from 0.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.node_type_mapping = {}  # string -> int\n",
    "        self.relationship_type_mapping = {}  # string -> int\n",
    "        self.reverse_node_type_mapping = {}  # int -> string\n",
    "        self.reverse_relationship_type_mapping = {}  # int -> string\n",
    "        self.global_to_local_mapping = {}  # For reference: global_id -> (node_type, local_id)\n",
    "        \n",
    "    def load_and_prepare_primekg(self, nodes_csv_path: str, edges_csv_path: str):\n",
    "        \"\"\"\n",
    "        Load PrimeKG data and prepare it for bulk_load_heterogeneous_graph.\n",
    "        Each node type gets sequential IDs starting from 0.\n",
    "        \n",
    "        Args:\n",
    "            nodes_csv_path: Path to nodes CSV file\n",
    "            edges_csv_path: Path to edges CSV file\n",
    "            \n",
    "        Returns:\n",
    "            Tuple of (node_types_dict, edge_types_dict) ready for DGL loading\n",
    "        \"\"\"\n",
    "        print(\"Loading PrimeKG data...\")\n",
    "        start_time = time.time()\n",
    "        \n",
    "        # Load raw data\n",
    "        print(\"  Reading CSV files...\")\n",
    "        nodes_df = pd.read_csv(nodes_csv_path, low_memory=False)\n",
    "        edges_df = pd.read_csv(edges_csv_path, low_memory=False)\n",
    "        \n",
    "        print(f\"  Loaded {len(nodes_df):,} nodes and {len(edges_df):,} edges\")\n",
    "        \n",
    "        # Create type mappings\n",
    "        print(\"  Creating type mappings...\")\n",
    "        self._create_type_mappings(nodes_df, edges_df)\n",
    "        \n",
    "        # Prepare node data (sequential IDs starting from 0 for each type)\n",
    "        print(\"  Preparing node data...\")\n",
    "        node_types_dict = self._prepare_node_data(nodes_df)\n",
    "        \n",
    "        # Prepare edge data (using local IDs)\n",
    "        print(\"  Preparing edge data...\")\n",
    "        edge_types_dict = self._prepare_edge_data(edges_df, nodes_df)\n",
    "        \n",
    "        total_time = time.time() - start_time\n",
    "        print(f\"\\nData preparation completed in {total_time:.2f}s\")\n",
    "        \n",
    "        # Print summary\n",
    "        self._print_summary(node_types_dict, edge_types_dict)\n",
    "        \n",
    "        return node_types_dict, edge_types_dict, self.global_to_local_mapping\n",
    "    \n",
    "    def _create_type_mappings(self, nodes_df: pd.DataFrame, edges_df: pd.DataFrame):\n",
    "        \"\"\"Create mappings between string types and integer representations.\"\"\"\n",
    "        \n",
    "        # Node type mappings\n",
    "        unique_node_types = sorted(nodes_df['node_type'].unique())\n",
    "        self.node_type_mapping = {node_type: i for i, node_type in enumerate(unique_node_types)}\n",
    "        self.reverse_node_type_mapping = {i: node_type for node_type, i in self.node_type_mapping.items()}\n",
    "        \n",
    "        # Relationship type mappings\n",
    "        unique_rel_types = sorted(edges_df['relationship_type'].unique())\n",
    "        self.relationship_type_mapping = {rel_type: i for i, rel_type in enumerate(unique_rel_types)}\n",
    "        self.reverse_relationship_type_mapping = {i: rel_type for rel_type, i in self.relationship_type_mapping.items()}\n",
    "        \n",
    "        print(f\"    Found {len(unique_node_types)} node types: {unique_node_types}\")\n",
    "        print(f\"    Found {len(unique_rel_types)} relationship types: {unique_rel_types}\")\n",
    "    \n",
    "    def _prepare_node_data(self, nodes_df: pd.DataFrame) -> Dict[str, pd.DataFrame]:\n",
    "        \"\"\"\n",
    "        Group nodes by type and prepare DataFrames with sequential IDs starting from 0.\n",
    "        \n",
    "        Returns:\n",
    "            Dict mapping node_type_string -> DataFrame with columns ['node_id', 'name', 'metadata_source', 'node_type_id', 'original_global_id']\n",
    "        \"\"\"\n",
    "        node_types_dict = {}\n",
    "        \n",
    "        # Add numeric type ID to nodes\n",
    "        nodes_df_copy = nodes_df.copy()\n",
    "        nodes_df_copy['node_type_id'] = nodes_df_copy['node_type'].map(self.node_type_mapping)\n",
    "        \n",
    "        # Group by node type and assign sequential IDs starting from 0\n",
    "        for node_type_str, group_df in nodes_df_copy.groupby('node_type'):\n",
    "            # Sort by original ID for consistency\n",
    "            group_df = group_df.sort_values('id').reset_index(drop=True)\n",
    "            \n",
    "            # Create sequential IDs starting from 0\n",
    "            num_nodes = len(group_df)\n",
    "            \n",
    "            # Build global to local mapping for this node type\n",
    "            global_ids = group_df['id'].values\n",
    "            local_ids = np.arange(num_nodes)  # 0, 1, 2, ..., num_nodes-1\n",
    "            \n",
    "            # Store the mapping for edge processing\n",
    "            for local_id, global_id in zip(local_ids, global_ids):\n",
    "                self.global_to_local_mapping[global_id] = (node_type_str, local_id)\n",
    "            \n",
    "            # Prepare DataFrame for DGL\n",
    "            prepared_df = pd.DataFrame({\n",
    "                'node_id': local_ids,  # Sequential IDs starting from 0\n",
    "                'name': group_df['name'].values,\n",
    "                'metadata_source': group_df['metadata_source'].values,\n",
    "                'node_type_id': group_df['node_type_id'].values,\n",
    "                'original_global_id': global_ids  # Keep original for reference\n",
    "            })\n",
    "            \n",
    "            node_types_dict[node_type_str] = prepared_df\n",
    "            print(f\"    {node_type_str}: {num_nodes:,} nodes (IDs: 0 to {num_nodes-1})\")\n",
    "            \n",
    "        return node_types_dict\n",
    "    \n",
    "    def _prepare_edge_data(self, edges_df: pd.DataFrame, nodes_df: pd.DataFrame) -> Dict[Tuple[str, str, str], pd.DataFrame]:\n",
    "        \"\"\"\n",
    "        Prepare edge data grouped by (src_type, edge_type, dst_type) using local IDs.\n",
    "        \n",
    "        Returns:\n",
    "            Dict mapping (src_type, edge_type, dst_type) -> DataFrame with columns ['src', 'dst', 'relationship_type_id']\n",
    "        \"\"\"\n",
    "        # Create node ID to type mapping for fast lookup\n",
    "        node_id_to_type = dict(zip(nodes_df['id'], nodes_df['node_type']))\n",
    "        \n",
    "        # Add relationship type IDs\n",
    "        edges_df_copy = edges_df.copy()\n",
    "        edges_df_copy['relationship_type_id'] = edges_df_copy['relationship_type'].map(self.relationship_type_mapping)\n",
    "        \n",
    "        # Add source and target node types\n",
    "        edges_df_copy['src_type'] = edges_df_copy['source_id'].map(node_id_to_type)\n",
    "        edges_df_copy['dst_type'] = edges_df_copy['target_id'].map(node_id_to_type)\n",
    "        \n",
    "        # Filter out edges with unknown nodes\n",
    "        valid_mask = (edges_df_copy['src_type'].notna()) & (edges_df_copy['dst_type'].notna())\n",
    "        valid_edges = edges_df_copy[valid_mask]\n",
    "        \n",
    "        if len(valid_edges) < len(edges_df_copy):\n",
    "            print(f\"    Warning: Filtered out {len(edges_df_copy) - len(valid_edges)} edges with unknown nodes\")\n",
    "        \n",
    "        # Group by (src_type, relationship_type, dst_type)\n",
    "        edge_types_dict = {}\n",
    "        \n",
    "        for (src_type, rel_type, dst_type), group_df in valid_edges.groupby(['src_type', 'relationship_type', 'dst_type']):\n",
    "            print(f\"    Processing {src_type} --[{rel_type}]--> {dst_type}: {len(group_df):,} edges\")\n",
    "            \n",
    "            # VECTORIZED APPROACH - Much faster than loops\n",
    "            group_df_reset = group_df.reset_index(drop=True)\n",
    "            \n",
    "            # Create mapping functions for this specific edge type\n",
    "            src_type_mapping = {global_id: local_id for global_id, (nt, local_id) in self.global_to_local_mapping.items() if nt == src_type}\n",
    "            dst_type_mapping = {global_id: local_id for global_id, (nt, local_id) in self.global_to_local_mapping.items() if nt == dst_type}\n",
    "            \n",
    "            # Vectorized mapping using pandas map\n",
    "            group_df_reset['src_local'] = group_df_reset['source_id'].map(src_type_mapping)\n",
    "            group_df_reset['dst_local'] = group_df_reset['target_id'].map(dst_type_mapping)\n",
    "            \n",
    "            # Filter valid edges (both src and dst must be mapped)\n",
    "            valid_mask = (group_df_reset['src_local'].notna()) & (group_df_reset['dst_local'].notna())\n",
    "            valid_edges_df = group_df_reset[valid_mask]\n",
    "            \n",
    "            if len(valid_edges_df) == 0:\n",
    "                print(f\"      Warning: No valid edges found for {src_type}-{rel_type}->{dst_type}\")\n",
    "                continue\n",
    "            \n",
    "            # Create edge DataFrame with local node IDs\n",
    "            edge_df = pd.DataFrame({\n",
    "                'src': valid_edges_df['src_local'].astype(int).values,  # Local IDs (0-based for each node type)\n",
    "                'dst': valid_edges_df['dst_local'].astype(int).values,  # Local IDs (0-based for each node type)\n",
    "                'relationship_type_id': valid_edges_df['relationship_type_id'].values,\n",
    "                'original_src_id': valid_edges_df['source_id'].values,  # Keep original for reference\n",
    "                'original_dst_id': valid_edges_df['target_id'].values   # Keep original for reference\n",
    "            })\n",
    "            \n",
    "            edge_types_dict[(src_type, rel_type, dst_type)] = edge_df\n",
    "            print(f\"      Created {len(edge_df):,} valid edges\")\n",
    "            \n",
    "        return edge_types_dict\n",
    "    \n",
    "    def _print_summary(self, node_types_dict: Dict[str, pd.DataFrame], \n",
    "                      edge_types_dict: Dict[Tuple[str, str, str], pd.DataFrame]):\n",
    "        \"\"\"Print summary of prepared data.\"\"\"\n",
    "        print(\"\\n\" + \"=\"*60)\n",
    "        print(\"PRIMEKG DATA PREPARATION SUMMARY\")\n",
    "        print(\"=\"*60)\n",
    "        \n",
    "        print(\"\\nNode Type Mappings:\")\n",
    "        for str_type, int_type in self.node_type_mapping.items():\n",
    "            count = len(node_types_dict.get(str_type, []))\n",
    "            print(f\"  {int_type}: {str_type} ({count:,} nodes, IDs: 0 to {count-1})\")\n",
    "        \n",
    "        print(\"\\nRelationship Type Mappings:\")\n",
    "        for str_type, int_type in self.relationship_type_mapping.items():\n",
    "            print(f\"  {int_type}: {str_type}\")\n",
    "        \n",
    "        print(\"\\nPrepared Node Types:\")\n",
    "        total_nodes = 0\n",
    "        for node_type, df in node_types_dict.items():\n",
    "            min_id = df['node_id'].min()\n",
    "            max_id = df['node_id'].max()\n",
    "            print(f\"  {node_type}: {len(df):,} nodes (local IDs: {min_id} to {max_id})\")\n",
    "            total_nodes += len(df)\n",
    "        print(f\"  TOTAL: {total_nodes:,} nodes\")\n",
    "        \n",
    "        print(\"\\nPrepared Edge Types:\")\n",
    "        total_edges = 0\n",
    "        for (src_type, edge_type, dst_type), df in edge_types_dict.items():\n",
    "            print(f\"  {src_type} --[{edge_type}]--> {dst_type}: {len(df):,} edges\")\n",
    "            total_edges += len(df)\n",
    "        print(f\"  TOTAL: {total_edges:,} edges\")\n",
    "        \n",
    "        print(\"\\nData Format Verification:\")\n",
    "        for node_type, df in node_types_dict.items():\n",
    "            assert df['node_id'].min() == 0, f\"Node IDs for {node_type} don't start at 0!\"\n",
    "            assert df['node_id'].max() == len(df) - 1, f\"Node IDs for {node_type} are not sequential!\"\n",
    "            print(f\"  ✅ {node_type}: Sequential IDs 0 to {len(df)-1}\")\n",
    "        \n",
    "        print(\"=\"*60)\n",
    "    \n",
    "    def get_type_mappings(self):\n",
    "        \"\"\"Return the type mappings for reference.\"\"\"\n",
    "        return {\n",
    "            'node_types': self.node_type_mapping,\n",
    "            'relationship_types': self.relationship_type_mapping,\n",
    "            'reverse_node_types': self.reverse_node_type_mapping,\n",
    "            'reverse_relationship_types': self.reverse_relationship_type_mapping\n",
    "        }\n",
    "    \n",
    "    def get_global_to_local_mapping(self):\n",
    "        \"\"\"Return the global to local ID mapping for reference.\"\"\"\n",
    "        return self.global_to_local_mapping.copy()\n",
    "    \n",
    "    def global_id_to_local(self, global_id: int) -> Tuple[str, int]:\n",
    "        \"\"\"Convert a global node ID to (node_type, local_id).\"\"\"\n",
    "        if global_id in self.global_to_local_mapping:\n",
    "            return self.global_to_local_mapping[global_id]\n",
    "        else:\n",
    "            raise ValueError(f\"Global ID {global_id} not found in mapping\")\n",
    "    \n",
    "    def local_id_to_global(self, node_type: str, local_id: int) -> int:\n",
    "        \"\"\"Convert (node_type, local_id) to global node ID.\"\"\"\n",
    "        for global_id, (nt, lid) in self.global_to_local_mapping.items():\n",
    "            if nt == node_type and lid == local_id:\n",
    "                return global_id\n",
    "        raise ValueError(f\"Local ID ({node_type}, {local_id}) not found in mapping\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3f43c74",
   "metadata": {},
   "outputs": [],
   "source": [
    "from DeepGraphDB import DeepGraphDB\n",
    "import torch\n",
    "\n",
    "db = DeepGraphDB()\n",
    "# Initialize the loader\n",
    "loader = PrimeKGLoader()\n",
    "\n",
    "# Load and prepare data\n",
    "nodes_csv = \"nodes.csv\"  # Replace with your actual path\n",
    "edges_csv = \"edges.csv\"  # Replace with your actual path\n",
    "\n",
    "node_types_dict, edge_types_dict, mapping = loader.load_and_prepare_primekg(nodes_csv, edges_csv)\n",
    "\n",
    "    \n",
    "# Get type mappings for reference\n",
    "mappings = loader.get_type_mappings()\n",
    "print(\"\\nType mappings created:\")\n",
    "print(\"Node types:\", mappings['node_types'])\n",
    "print(\"Relationship types:\", mappings['relationship_types'])\n",
    "\n",
    "# Verify data format\n",
    "print(\"\\nData format verification:\")\n",
    "for node_type, df in node_types_dict.items():\n",
    "    print(f\"  {node_type}: node_id range {df['node_id'].min()}-{df['node_id'].max()}\")\n",
    "\n",
    "# Now you can use this data with your DGL graph analyzer\n",
    "print(\"\\nReady to load into DGL!\")\n",
    "print(\"Use: analyzer.bulk_load_heterogeneous_graph(node_types_dict, edge_types_dict)\")\n",
    "db.bulk_load_heterogeneous_graph(node_types_dict, edge_types_dict)\n",
    "db.set_mappings(loader.node_type_mapping, loader.relationship_type_mapping)\n",
    "db.set_global_to_local_mapping(mapping)\n",
    "\n",
    "x = torch.rand(max(db.global_to_local_mapping.keys())+1, 128)\n",
    "db.load_node_features_for_gnn(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6c496b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import dgl\n",
    "import dgl.nn as dglnn\n",
    "import dgl.function as fn\n",
    "from dgl.dataloading import (\n",
    "    DataLoader, \n",
    "    MultiLayerNeighborSampler, \n",
    "    as_edge_prediction_sampler\n",
    ")\n",
    "from sklearn.metrics import roc_auc_score, average_precision_score\n",
    "import itertools\n",
    "from typing import Dict, List, Tuple, Optional\n",
    "from collections import defaultdict\n",
    "\n",
    "# Set PyTorch backend for DGL\n",
    "os.environ[\"DGLBACKEND\"] = \"pytorch\"\n",
    "\n",
    "class HeteroGraphSAGE(nn.Module):\n",
    "    \"\"\"\n",
    "    Heterogeneous GraphSAGE implementation with attention mechanism\n",
    "    \"\"\"\n",
    "    def __init__(self, node_types, edge_types, in_feats, hidden_feats, out_feats, \n",
    "                 num_layers=2, aggregator_type='mean', use_attention=True):\n",
    "        super().__init__()\n",
    "        self.node_types = node_types\n",
    "        self.edge_types = edge_types\n",
    "        self.num_layers = num_layers\n",
    "        self.use_attention = use_attention\n",
    "\n",
    "        print(node_types)\n",
    "        \n",
    "        # Input projection for different node types\n",
    "        self.input_proj = nn.ModuleDict({\n",
    "            ntype: nn.Linear(in_feats[ntype] if isinstance(in_feats, dict) else in_feats, hidden_feats)\n",
    "            for ntype in node_types\n",
    "        })\n",
    "\n",
    "        print(self.input_proj)\n",
    "        \n",
    "        # GraphSAGE layers\n",
    "        self.sage_layers = nn.ModuleList()\n",
    "        self.layer_norms = nn.ModuleList()\n",
    "        \n",
    "        for i in range(num_layers):\n",
    "            in_dim = hidden_feats\n",
    "            out_dim = hidden_feats if i < num_layers - 1 else out_feats\n",
    "            \n",
    "            # Use different aggregators for different layers\n",
    "            conv_dict = {}\n",
    "            for etype in edge_types:\n",
    "                conv_dict[etype] = dglnn.SAGEConv(\n",
    "                    in_feats=in_dim,\n",
    "                    out_feats=out_dim,\n",
    "                    aggregator_type=aggregator_type,\n",
    "                    norm=F.relu if i < num_layers - 1 else None,\n",
    "                    activation=F.relu if i < num_layers - 1 else None\n",
    "                )\n",
    "            \n",
    "            self.sage_layers.append(\n",
    "                dglnn.HeteroGraphConv(conv_dict, aggregate='sum')\n",
    "            )\n",
    "            \n",
    "            # Layer norm for each layer with correct dimensions\n",
    "            layer_norm_dict = nn.ModuleDict({\n",
    "                ntype: nn.LayerNorm(out_dim) for ntype in node_types\n",
    "            })\n",
    "            self.layer_norms.append(layer_norm_dict)\n",
    "        \n",
    "        # Attention mechanism for heterogeneous message passing\n",
    "        if use_attention:\n",
    "            self.attention = nn.ModuleDict({\n",
    "                ntype: nn.MultiheadAttention(\n",
    "                    embed_dim=out_feats,\n",
    "                    num_heads=4,\n",
    "                    dropout=0.1,\n",
    "                    batch_first=True\n",
    "                ) for ntype in node_types\n",
    "            })\n",
    "        \n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "        \n",
    "    def forward(self, blocks, x):\n",
    "        h = {}\n",
    "        \n",
    "        # Input projection\n",
    "        for ntype in self.node_types:\n",
    "            if ntype in x:\n",
    "                h[ntype] = self.input_proj[ntype](x[ntype])\n",
    "        \n",
    "        # Forward through SAGE layers\n",
    "        for i, (layer, block) in enumerate(zip(self.sage_layers, blocks)):\n",
    "            h_new = layer(block, h)\n",
    "            \n",
    "            # Apply attention if enabled (only on final layer)\n",
    "            if self.use_attention and i == len(self.sage_layers) - 1:\n",
    "                for ntype in h_new:\n",
    "                    if h_new[ntype].dim() == 2:\n",
    "                        # Add sequence dimension for attention\n",
    "                        h_input = h_new[ntype].unsqueeze(1)  # [N, 1, D]\n",
    "                        attn_out, _ = self.attention[ntype](h_input, h_input, h_input)\n",
    "                        h_new[ntype] = attn_out.squeeze(1)  # [N, D]\n",
    "            \n",
    "            # Layer normalization and residual connection\n",
    "            if i > 0:  # Skip connection from previous layer\n",
    "                for ntype in h_new:\n",
    "                    if ntype in h and h[ntype].shape == h_new[ntype].shape:\n",
    "                        h_new[ntype] = h_new[ntype] + h[ntype]\n",
    "            \n",
    "            # Apply layer norm and dropout with correct dimensions\n",
    "            for ntype in h_new:\n",
    "                h_new[ntype] = self.layer_norms[i][ntype](h_new[ntype])\n",
    "                if i < len(self.sage_layers) - 1:\n",
    "                    h_new[ntype] = self.dropout(h_new[ntype])\n",
    "            \n",
    "            h = h_new\n",
    "        \n",
    "        return h\n",
    "\n",
    "class MultiEdgeTypePredictor(nn.Module):\n",
    "    \"\"\"\n",
    "    Advanced predictor that can handle multiple edge types simultaneously\n",
    "    \"\"\"\n",
    "    def __init__(self, in_features, hidden_features=128, edge_types=None):\n",
    "        super().__init__()\n",
    "        self.edge_types = edge_types or []\n",
    "        \n",
    "        # Shared feature transformation\n",
    "        self.feature_transform = nn.Sequential(\n",
    "            nn.Linear(in_features * 2, hidden_features),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.1),\n",
    "            nn.BatchNorm1d(hidden_features)\n",
    "        )\n",
    "        \n",
    "        # Edge type specific predictors\n",
    "        self.edge_predictors = nn.ModuleDict({\n",
    "            f\"{etype[0]}_{etype[1]}_{etype[2]}\": nn.Sequential(\n",
    "                nn.Linear(hidden_features, hidden_features // 2),\n",
    "                nn.ReLU(),\n",
    "                nn.Dropout(0.1),\n",
    "                nn.Linear(hidden_features // 2, 1)\n",
    "            ) for etype in self.edge_types\n",
    "        })\n",
    "        \n",
    "        # Edge type embeddings for better prediction\n",
    "        self.edge_type_embeddings = nn.Embedding(len(self.edge_types), hidden_features)\n",
    "        \n",
    "    def forward(self, graph, h, etype):\n",
    "        with graph.local_scope():\n",
    "            graph.ndata['h'] = h\n",
    "            \n",
    "            # Concatenate source and destination features\n",
    "            src_type, edge_type, dst_type = etype\n",
    "            src_nodes, dst_nodes = graph.edges(etype=etype)\n",
    "            \n",
    "            src_feat = h[src_type][src_nodes]\n",
    "            dst_feat = h[dst_type][dst_nodes]\n",
    "            edge_feat = torch.cat([src_feat, dst_feat], dim=1)\n",
    "            \n",
    "            # Transform features\n",
    "            transformed_feat = self.feature_transform(edge_feat)\n",
    "            \n",
    "            # Add edge type embedding\n",
    "            etype_key = f\"{etype[0]}_{etype[1]}_{etype[2]}\"\n",
    "            if etype_key in self.edge_predictors and etype in self.edge_types:\n",
    "                # Get edge type embedding\n",
    "                etype_idx = torch.tensor([self.edge_types.index(etype)], device=edge_feat.device)\n",
    "                etype_emb = self.edge_type_embeddings(etype_idx).expand(transformed_feat.size(0), -1)\n",
    "                \n",
    "                # Combine with edge features\n",
    "                combined_feat = transformed_feat + etype_emb\n",
    "                \n",
    "                # Predict scores\n",
    "                scores = self.edge_predictors[etype_key](combined_feat).squeeze()\n",
    "            else:\n",
    "                # Fallback to simple dot product\n",
    "                scores = (src_feat * dst_feat).sum(dim=1)\n",
    "            \n",
    "            return scores\n",
    "\n",
    "class HeteroMLPPredictor(nn.Module):\n",
    "    \"\"\"Enhanced MLP predictor with residual connections\"\"\"\n",
    "    def __init__(self, in_features, hidden_features=128):\n",
    "        super().__init__()\n",
    "        self.input_proj = nn.Linear(in_features * 2, hidden_features)\n",
    "        \n",
    "        # Residual blocks\n",
    "        self.residual_blocks = nn.ModuleList([\n",
    "            nn.Sequential(\n",
    "                nn.Linear(hidden_features, hidden_features),\n",
    "                nn.ReLU(),\n",
    "                nn.Dropout(0.1),\n",
    "                nn.Linear(hidden_features, hidden_features),\n",
    "                nn.ReLU()\n",
    "            ) for _ in range(2)\n",
    "        ])\n",
    "        \n",
    "        self.output_proj = nn.Sequential(\n",
    "            nn.Dropout(0.1),\n",
    "            nn.Linear(hidden_features, 1)\n",
    "        )\n",
    "        \n",
    "    def forward(self, graph, h, etype):\n",
    "        with graph.local_scope():\n",
    "            src_type, edge_type, dst_type = etype\n",
    "            src_nodes, dst_nodes = graph.edges(etype=etype)\n",
    "            \n",
    "            src_feat = h[src_type][src_nodes]\n",
    "            dst_feat = h[dst_type][dst_nodes]\n",
    "            edge_feat = torch.cat([src_feat, dst_feat], dim=1)\n",
    "            \n",
    "            # Input projection\n",
    "            x = self.input_proj(edge_feat)\n",
    "            \n",
    "            # Residual blocks\n",
    "            for block in self.residual_blocks:\n",
    "                residual = x\n",
    "                x = block(x) + residual\n",
    "            \n",
    "            # Output projection\n",
    "            scores = self.output_proj(x).squeeze()\n",
    "            return scores\n",
    "\n",
    "class AdvancedHeteroLinkPredictor(nn.Module):\n",
    "    \"\"\"\n",
    "    Advanced heterogeneous link prediction model with multiple edge type support\n",
    "    \"\"\"\n",
    "    def __init__(self, node_types, edge_types, in_feats, hidden_feats, out_feats, \n",
    "                 num_layers=3, use_attention=True, predictor_type='multi_edge', target_etypes=None):\n",
    "        super().__init__()\n",
    "        self.node_types = node_types\n",
    "        self.edge_types = edge_types\n",
    "        self.target_etypes = target_etypes or edge_types\n",
    "        \n",
    "        # Advanced GNN backbone (uses all edge types for message passing)\n",
    "        self.gnn = HeteroGraphSAGE(\n",
    "            node_types=node_types,\n",
    "            edge_types=edge_types,\n",
    "            in_feats=in_feats,\n",
    "            hidden_feats=hidden_feats,\n",
    "            out_feats=out_feats,\n",
    "            num_layers=num_layers,\n",
    "            use_attention=use_attention\n",
    "        )\n",
    "        \n",
    "        # Advanced predictor (only for target edge types)\n",
    "        if predictor_type == 'multi_edge':\n",
    "            self.predictor = MultiEdgeTypePredictor(out_feats, hidden_feats, self.target_etypes)\n",
    "        else:\n",
    "            self.predictor = HeteroMLPPredictor(out_feats)\n",
    "            \n",
    "    def forward(self, pos_graph, neg_graph, blocks, x, etype):\n",
    "        # Get node representations\n",
    "        h = self.gnn(blocks, x)\n",
    "        \n",
    "        # Compute scores\n",
    "        pos_score = self.predictor(pos_graph, h, etype)\n",
    "        neg_score = self.predictor(neg_graph, h, etype)\n",
    "        \n",
    "        return pos_score, neg_score\n",
    "    \n",
    "    def get_embeddings(self, graph, x):\n",
    "        \"\"\"\n",
    "        Get node embeddings for the entire graph\n",
    "        \"\"\"\n",
    "        h = self.gnn([graph], x)\n",
    "        return {ntype: h[ntype].detach() for ntype in self.node_types}\n",
    "\n",
    "def advanced_negative_sampling(graph, etype, k=1, method='uniform'):\n",
    "    \"\"\"\n",
    "    Advanced negative sampling with different strategies\n",
    "    \"\"\"\n",
    "    if method == 'uniform':\n",
    "        return negative_sampling(graph, etype, k)\n",
    "    elif method == 'popularity_based':\n",
    "        # Sample negative examples based on node popularity\n",
    "        src_type, _, dst_type = etype\n",
    "        src, dst = graph.edges(etype=etype)\n",
    "        \n",
    "        # Calculate node degrees for popularity-based sampling\n",
    "        try:\n",
    "            dst_degrees = graph.in_degrees(graph.nodes(dst_type), etype=etype).float()\n",
    "        except:\n",
    "            # Fallback to uniform sampling if degree calculation fails\n",
    "            return negative_sampling(graph, etype, k)\n",
    "            \n",
    "        if dst_degrees.sum() == 0:\n",
    "            # Fallback to uniform sampling if no degrees\n",
    "            return negative_sampling(graph, etype, k)\n",
    "            \n",
    "        dst_probs = dst_degrees / dst_degrees.sum()\n",
    "        \n",
    "        # Sample negative destinations based on popularity\n",
    "        neg_dst = torch.multinomial(dst_probs, len(src) * k, replacement=True)\n",
    "        neg_src = src.repeat_interleave(k)\n",
    "        \n",
    "        # Create negative graph\n",
    "        neg_graph = dgl.heterograph(\n",
    "            {etype: (neg_src, neg_dst)},\n",
    "            num_nodes_dict={ntype: graph.num_nodes(ntype) for ntype in graph.ntypes}\n",
    "        )\n",
    "        return neg_graph\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown negative sampling method: {method}\")\n",
    "\n",
    "def negative_sampling(graph, etype, k=1):\n",
    "    \"\"\"\n",
    "    Standard negative sampling implementation using manual sampling\n",
    "    \"\"\"\n",
    "    src_type, _, dst_type = etype\n",
    "    src, dst = graph.edges(etype=etype)\n",
    "    \n",
    "    # Manual negative sampling\n",
    "    num_pos_edges = len(src)\n",
    "    num_neg_edges = num_pos_edges * k\n",
    "    \n",
    "    # Sample negative source nodes (same as positive)\n",
    "    neg_src = src.repeat_interleave(k)\n",
    "    \n",
    "    # Sample negative destination nodes uniformly\n",
    "    num_dst_nodes = graph.num_nodes(dst_type)\n",
    "    neg_dst = torch.randint(0, num_dst_nodes, (num_neg_edges,), device=src.device)\n",
    "    \n",
    "    # Create negative graph\n",
    "    neg_graph = dgl.heterograph(\n",
    "        {etype: (neg_src, neg_dst)},\n",
    "        num_nodes_dict={ntype: graph.num_nodes(ntype) for ntype in graph.ntypes}\n",
    "    )\n",
    "    \n",
    "    return neg_graph\n",
    "\n",
    "def multi_metric_evaluation(pos_scores, neg_scores):\n",
    "    \"\"\"\n",
    "    Compute multiple evaluation metrics\n",
    "    \"\"\"\n",
    "    scores = torch.cat([pos_scores, neg_scores]).detach().cpu().numpy()\n",
    "    labels = torch.cat([\n",
    "        torch.ones(pos_scores.shape[0]),\n",
    "        torch.zeros(neg_scores.shape[0])\n",
    "    ]).cpu().numpy()\n",
    "    \n",
    "    auc = roc_auc_score(labels, scores)\n",
    "    ap = average_precision_score(labels, scores)\n",
    "    \n",
    "    # Compute Hit@K metrics\n",
    "    k_values = [1, 5, 10]\n",
    "    hit_at_k = {}\n",
    "    \n",
    "    for k in k_values:\n",
    "        # Sort scores in descending order\n",
    "        sorted_indices = np.argsort(scores)[::-1]\n",
    "        top_k_labels = labels[sorted_indices[:k]]\n",
    "        hit_at_k[f'Hit@{k}'] = np.sum(top_k_labels) / min(k, np.sum(labels))\n",
    "    \n",
    "    return {\n",
    "        'AUC': auc,\n",
    "        'AP': ap,\n",
    "        **hit_at_k\n",
    "    }\n",
    "\n",
    "# Enhanced loss function with margin-based ranking\n",
    "def compute_margin_loss(pos_score, neg_score, margin=1.0):\n",
    "    \"\"\"\n",
    "    Compute margin-based ranking loss\n",
    "    \"\"\"\n",
    "    # Expand dimensions for broadcasting\n",
    "    pos_score = pos_score.unsqueeze(1)  # [batch_size, 1]\n",
    "    neg_score = neg_score.unsqueeze(0)  # [1, num_neg]\n",
    "    \n",
    "    # Compute margin loss\n",
    "    loss = torch.clamp(margin - pos_score + neg_score, min=0)\n",
    "    return loss.mean()\n",
    "\n",
    "def compute_loss(pos_score, neg_score, loss_type='bce'):\n",
    "    \"\"\"\n",
    "    Compute loss with different loss types\n",
    "    \"\"\"\n",
    "    if loss_type == 'bce':\n",
    "        pos_label = torch.ones_like(pos_score)\n",
    "        neg_label = torch.zeros_like(neg_score)\n",
    "        scores = torch.cat([pos_score, neg_score])\n",
    "        labels = torch.cat([pos_label, neg_label])\n",
    "        return F.binary_cross_entropy_with_logits(scores, labels)\n",
    "    elif loss_type == 'margin':\n",
    "        return compute_margin_loss(pos_score, neg_score)\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown loss type: {loss_type}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14af7c73",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import dgl\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def split_edges_consistent(graph, target_etypes, train_ratio=0.7, val_ratio=0.15, test_ratio=0.15, random_state=42):\n",
    "    \"\"\"\n",
    "    Split edges consistently across different edge types in a heterogeneous graph.\n",
    "    \n",
    "    Args:\n",
    "        graph: DGL heterogeneous graph\n",
    "        target_etypes: List of edge types to split\n",
    "        train_ratio: Ratio for training set\n",
    "        val_ratio: Ratio for validation set  \n",
    "        test_ratio: Ratio for test set\n",
    "        random_state: Random seed for reproducibility\n",
    "    \n",
    "    Returns:\n",
    "        Dictionary containing train/val/test edge indices for each edge type\n",
    "    \"\"\"\n",
    "    assert abs(train_ratio + val_ratio + test_ratio - 1.0) < 1e-6, \"Ratios must sum to 1.0\"\n",
    "    \n",
    "    edge_splits = {}\n",
    "    np.random.seed(random_state)\n",
    "    \n",
    "    for etype in target_etypes:\n",
    "        src, dst = graph.edges(etype=etype)\n",
    "        num_edges = len(src)\n",
    "        \n",
    "        if num_edges == 0:\n",
    "            edge_splits[etype] = {\n",
    "                'train': {'src': torch.tensor([]), 'dst': torch.tensor([])},\n",
    "                'val': {'src': torch.tensor([]), 'dst': torch.tensor([])},\n",
    "                'test': {'src': torch.tensor([]), 'dst': torch.tensor([])}\n",
    "            }\n",
    "            continue\n",
    "        \n",
    "        # Create edge indices\n",
    "        edge_indices = np.arange(num_edges)\n",
    "        \n",
    "        # First split: train vs (val + test)\n",
    "        train_indices, temp_indices = train_test_split(\n",
    "            edge_indices, \n",
    "            train_size=train_ratio, \n",
    "            random_state=random_state\n",
    "        )\n",
    "        \n",
    "        # Second split: val vs test from the remaining\n",
    "        val_size = val_ratio / (val_ratio + test_ratio)\n",
    "        val_indices, test_indices = train_test_split(\n",
    "            temp_indices, \n",
    "            train_size=val_size, \n",
    "            random_state=random_state\n",
    "        )\n",
    "        \n",
    "        # Store the splits\n",
    "        edge_splits[etype] = {\n",
    "            'train': {\n",
    "                'src': src[train_indices],\n",
    "                'dst': dst[train_indices]\n",
    "            },\n",
    "            'val': {\n",
    "                'src': src[val_indices], \n",
    "                'dst': dst[val_indices]\n",
    "            },\n",
    "            'test': {\n",
    "                'src': src[test_indices],\n",
    "                'dst': dst[test_indices]\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        print(f\"Edge type {etype}: {len(train_indices)} train, {len(val_indices)} val, {len(test_indices)} test\")\n",
    "    \n",
    "    return edge_splits\n",
    "\n",
    "def create_train_graph(graph, edge_splits, target_etypes):\n",
    "    \"\"\"\n",
    "    Create a training graph that only contains training edges.\n",
    "    \"\"\"\n",
    "    train_edge_dict = {}\n",
    "    \n",
    "    # Add all non-target edge types (keep full connectivity for message passing)\n",
    "    for etype in graph.canonical_etypes:\n",
    "        if etype not in target_etypes:\n",
    "            src, dst = graph.edges(etype=etype)\n",
    "            train_edge_dict[etype] = (src, dst)\n",
    "        else:\n",
    "            # Only add training edges for target edge types\n",
    "            train_edges = edge_splits[etype]['train']\n",
    "            if len(train_edges['src']) > 0:\n",
    "                train_edge_dict[etype] = (train_edges['src'], train_edges['dst'])\n",
    "    \n",
    "    # Create training graph\n",
    "    train_graph = dgl.heterograph(\n",
    "        train_edge_dict,\n",
    "        num_nodes_dict={ntype: graph.num_nodes(ntype) for ntype in graph.ntypes}\n",
    "    )\n",
    "    \n",
    "    # Copy node features\n",
    "    for ntype in graph.ntypes:\n",
    "        if graph.nodes[ntype].data:\n",
    "            for key, value in graph.nodes[ntype].data.items():\n",
    "                train_graph.nodes[ntype].data[key] = value\n",
    "    \n",
    "    return train_graph\n",
    "\n",
    "def evaluate_on_split(model, graph, edge_splits, target_etypes, split_name, device, num_neg_samples=5):\n",
    "    \"\"\"\n",
    "    Evaluate model on a specific data split (val or test) using multiple negative samples.\n",
    "    \n",
    "    Args:\n",
    "        model: The trained model\n",
    "        graph: Full graph for message passing\n",
    "        edge_splits: Dictionary containing edge splits\n",
    "        target_etypes: List of target edge types\n",
    "        split_name: 'val' or 'test'\n",
    "        device: Device to run evaluation on\n",
    "        num_neg_samples: Number of different negative graphs to average over\n",
    "    \n",
    "    Returns:\n",
    "        split_metrics: Dictionary with averaged metrics\n",
    "        metrics_std: Dictionary with standard deviations (only returned for final evaluation)\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    split_metrics = defaultdict(list)\n",
    "    all_metrics = defaultdict(lambda: defaultdict(list))  # For calculating std\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for target_etype in target_etypes:\n",
    "            split_edges = edge_splits[target_etype][split_name]\n",
    "            \n",
    "            if len(split_edges['src']) == 0:\n",
    "                continue\n",
    "            \n",
    "            # Create positive graph for evaluation\n",
    "            pos_graph = dgl.heterograph(\n",
    "                {target_etype: (split_edges['src'], split_edges['dst'])},\n",
    "                num_nodes_dict={ntype: graph.num_nodes(ntype) for ntype in graph.ntypes}\n",
    "            ).to(device)\n",
    "            \n",
    "            # Prepare input features\n",
    "            input_features = {ntype: graph.nodes[ntype].data['x'] for ntype in graph.ntypes}\n",
    "            \n",
    "            # Create blocks for GNN (using full graph for message passing)\n",
    "            blocks = [graph, graph, graph]\n",
    "            \n",
    "            # Evaluate with multiple negative samples\n",
    "            etype_metrics = defaultdict(list)\n",
    "            \n",
    "            for neg_sample_idx in range(num_neg_samples):\n",
    "                # Generate different negative samples for each iteration\n",
    "                neg_graph = advanced_negative_sampling(\n",
    "                    pos_graph, target_etype, k=1, method='uniform'\n",
    "                ).to(device)\n",
    "                \n",
    "                # Forward pass\n",
    "                pos_score, neg_score = model(pos_graph, neg_graph, blocks, input_features, target_etype)\n",
    "                \n",
    "                # Compute metrics for this negative sample\n",
    "                metrics = multi_metric_evaluation(pos_score, neg_score)\n",
    "                for metric_name, value in metrics.items():\n",
    "                    etype_metrics[metric_name].append(value)\n",
    "                    all_metrics[target_etype][metric_name].append(value)\n",
    "            \n",
    "            # Average metrics across all negative samples\n",
    "            for metric_name, values in etype_metrics.items():\n",
    "                avg_metric = np.mean(values)\n",
    "                split_metrics[f\"{target_etype}_{metric_name}\"].append(avg_metric)\n",
    "    \n",
    "    # Calculate standard deviations for detailed evaluation\n",
    "    metrics_std = {}\n",
    "    for etype in target_etypes:\n",
    "        for metric_name in all_metrics[etype]:\n",
    "            std_key = f\"{etype}_{metric_name}_std\"\n",
    "            metrics_std[std_key] = np.std(all_metrics[etype][metric_name])\n",
    "    \n",
    "    return split_metrics, metrics_std\n",
    "\n",
    "# Your existing code for graph creation and model setup\n",
    "graph = db.graph\n",
    "\n",
    "print(f\"Graph created with {graph.num_nodes()} nodes and {graph.num_edges()} edges\")\n",
    "print(f\"Node types: {graph.ntypes}\")\n",
    "print(f\"Edge types: {graph.etypes}\")\n",
    "\n",
    "# Create model\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "node_types = graph.ntypes\n",
    "edge_types = graph.etypes\n",
    "\n",
    "in_feats = {ntype: 128 for ntype in node_types}\n",
    "target_entities = ['drug', 'disease', 'geneprotein', 'effectphenotype']\n",
    "\n",
    "# Choose multiple edge types for prediction\n",
    "target_etypes = [ctype for ctype in graph.canonical_etypes if ctype[0] in target_entities and ctype[2] in target_entities]\n",
    "# target_etypes = [ctype for ctype in graph.canonical_etypes]\n",
    "\n",
    "print(f\"Target edge types for prediction: {target_etypes}\")\n",
    "\n",
    "hidden_feats = 256\n",
    "out_feats = 128\n",
    "\n",
    "model = AdvancedHeteroLinkPredictor(\n",
    "    node_types=node_types,\n",
    "    edge_types=edge_types,  # All edge types for GNN layers\n",
    "    in_feats=in_feats,\n",
    "    hidden_feats=hidden_feats,\n",
    "    out_feats=out_feats,\n",
    "    num_layers=3,\n",
    "    use_attention=True,\n",
    "    predictor_type='multi_edge',\n",
    "    target_etypes=target_etypes  # Only target edge types for prediction\n",
    ").to(device)\n",
    "\n",
    "print(f\"Model created with {sum(p.numel() for p in model.parameters())} parameters\")\n",
    "\n",
    "# ==================== NEW: Edge Splitting ====================\n",
    "print(\"\\nSplitting edges into train/val/test sets...\")\n",
    "edge_splits = split_edges_consistent(\n",
    "    graph, \n",
    "    target_etypes, \n",
    "    train_ratio=0.7, \n",
    "    val_ratio=0.15, \n",
    "    test_ratio=0.15,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Create training graph (only contains training edges for target edge types)\n",
    "train_graph = create_train_graph(graph, edge_splits, target_etypes)\n",
    "print(f\"Training graph created with {train_graph.num_edges()} edges\")\n",
    "\n",
    "# Move graphs to device\n",
    "graph = graph.to(device)\n",
    "train_graph = train_graph.to(device)\n",
    "\n",
    "# Training configuration\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=0.001, weight_decay=1e-5)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, patience=10, factor=0.5)\n",
    "\n",
    "# ==================== MODIFIED: Training Loop ====================\n",
    "print(\"Starting training with proper train/val splits...\")\n",
    "best_val_metrics = {etype: 0.0 for etype in target_etypes}\n",
    "patience_counter = 0\n",
    "max_patience = 20\n",
    "\n",
    "for epoch in range(100):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    \n",
    "    # Train on each edge type using only training edges\n",
    "    for target_etype in target_etypes:\n",
    "        train_edges = edge_splits[target_etype]['train']\n",
    "        \n",
    "        if len(train_edges['src']) == 0:\n",
    "            continue\n",
    "        \n",
    "        src, dst = train_edges['src'], train_edges['dst']\n",
    "        \n",
    "        # Create mini-batches\n",
    "        batch_size = min(1000000, len(src))\n",
    "        num_batches = (len(src) + batch_size - 1) // batch_size\n",
    "        \n",
    "        for batch_idx in range(num_batches):\n",
    "            start_idx = batch_idx * batch_size\n",
    "            end_idx = min((batch_idx + 1) * batch_size, len(src))\n",
    "            \n",
    "            batch_src = src[start_idx:end_idx]\n",
    "            batch_dst = dst[start_idx:end_idx]\n",
    "            \n",
    "            # Create positive graph for batch\n",
    "            pos_graph = dgl.heterograph(\n",
    "                {target_etype: (batch_src, batch_dst)},\n",
    "                num_nodes_dict={ntype: graph.num_nodes(ntype) for ntype in graph.ntypes}\n",
    "            ).to(device)\n",
    "            \n",
    "            # Generate negative samples\n",
    "            neg_graph = advanced_negative_sampling(\n",
    "                pos_graph, target_etype, k=1, method='uniform'\n",
    "            ).to(device)\n",
    "            \n",
    "            # Prepare input features (use full graph features)\n",
    "            input_features = {ntype: graph.nodes[ntype].data['x'] for ntype in node_types}\n",
    "            \n",
    "            # Create blocks for GNN (use full graph for message passing)\n",
    "            blocks = [graph, graph, graph]\n",
    "            \n",
    "            # Forward pass\n",
    "            pos_score, neg_score = model(pos_graph, neg_graph, blocks, input_features, target_etype)\n",
    "            \n",
    "            # Compute loss\n",
    "            loss = compute_loss(pos_score, neg_score)\n",
    "            \n",
    "            # Backward pass\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "            optimizer.step()\n",
    "            \n",
    "            total_loss += loss.item()\n",
    "    \n",
    "    # ==================== NEW: Validation Evaluation ====================\n",
    "    if epoch % 5 == 0:  # Evaluate every 5 epochs\n",
    "        # Evaluate on validation set\n",
    "        val_metrics = evaluate_on_split(model, graph, edge_splits, target_etypes, 'val', device)\n",
    "        \n",
    "        print(f\"\\nEpoch {epoch:03d} | Loss: {total_loss:.4f}\")\n",
    "        \n",
    "        # Track best validation metrics and calculate average\n",
    "        epoch_improved = False\n",
    "        epoch_aucs = []\n",
    "        for etype in target_etypes:\n",
    "            if f\"{etype}_AUC\" in val_metrics:\n",
    "                auc_values = val_metrics[f\"{etype}_AUC\"]\n",
    "                if auc_values:\n",
    "                    avg_auc = np.mean(auc_values)\n",
    "                    epoch_aucs.append(avg_auc)\n",
    "                    print(f\"  {etype} Val AUC: {avg_auc:.4f}\")\n",
    "                    \n",
    "                    if avg_auc > best_val_metrics[etype]:\n",
    "                        best_val_metrics[etype] = avg_auc\n",
    "                        epoch_improved = True\n",
    "        \n",
    "        # Print average AUC across all edge types\n",
    "        if epoch_aucs:\n",
    "            avg_auc_all = np.mean(epoch_aucs)\n",
    "            print(f\"  Average Val AUC: {avg_auc_all:.4f}\")\n",
    "        \n",
    "        # Early stopping logic\n",
    "        if epoch_improved:\n",
    "            patience_counter = 0\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "            \n",
    "        if patience_counter >= max_patience:\n",
    "            print(f\"\\nEarly stopping at epoch {epoch} (no improvement for {max_patience} evaluations)\")\n",
    "            break\n",
    "    \n",
    "    # Scheduler step\n",
    "    scheduler.step(total_loss)\n",
    "\n",
    "print(\"\\nTraining completed!\")\n",
    "\n",
    "# ==================== NEW: Final Evaluation ====================\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"FINAL EVALUATION\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Validation set evaluation\n",
    "print(\"\\nValidation Set Results:\")\n",
    "val_metrics = evaluate_on_split(model, graph, edge_splits, target_etypes, 'val', device)\n",
    "val_aucs = []\n",
    "for etype in target_etypes:\n",
    "    if f\"{etype}_AUC\" in val_metrics:\n",
    "        auc_values = val_metrics[f\"{etype}_AUC\"]\n",
    "        if auc_values:\n",
    "            avg_auc = np.mean(auc_values)\n",
    "            val_aucs.append(avg_auc)\n",
    "            print(f\"  {etype} AUC: {avg_auc:.4f}\")\n",
    "\n",
    "if val_aucs:\n",
    "    avg_val_auc = np.mean(val_aucs)\n",
    "    print(f\"  Average Val AUC: {avg_val_auc:.4f}\")\n",
    "\n",
    "# Test set evaluation  \n",
    "print(\"\\nTest Set Results:\")\n",
    "test_metrics = evaluate_on_split(model, graph, edge_splits, target_etypes, 'test', device)\n",
    "test_aucs = []\n",
    "for etype in target_etypes:\n",
    "    if f\"{etype}_AUC\" in test_metrics:\n",
    "        auc_values = test_metrics[f\"{etype}_AUC\"]\n",
    "        if auc_values:\n",
    "            avg_auc = np.mean(auc_values)\n",
    "            test_aucs.append(avg_auc)\n",
    "            print(f\"  {etype} AUC: {avg_auc:.4f}\")\n",
    "\n",
    "if test_aucs:\n",
    "    avg_test_auc = np.mean(test_aucs)\n",
    "    print(f\"  Average Test AUC: {avg_test_auc:.4f}\")\n",
    "\n",
    "print(\"\\nBest validation metrics achieved during training:\")\n",
    "best_val_aucs = []\n",
    "for etype, best_auc in best_val_metrics.items():\n",
    "    best_val_aucs.append(best_auc)\n",
    "    print(f\"  {etype}: {best_auc:.4f}\")\n",
    "\n",
    "if best_val_aucs:\n",
    "    avg_best_val_auc = np.mean(best_val_aucs)\n",
    "    print(f\"  Average Best Val AUC: {avg_best_val_auc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4c6cc7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "embs = model.get_embeddings(graph, {ntype: graph.nodes[ntype].data['x'] for ntype in node_types})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
