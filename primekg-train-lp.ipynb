{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f6a94a4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from typing import Dict, Tuple\n",
    "from collections import defaultdict\n",
    "import time\n",
    "\n",
    "class PrimeKGLoader:\n",
    "    \"\"\"\n",
    "    Prepares PrimeKG data for efficient loading into DGL heterogeneous graphs.\n",
    "    Each node type gets sequential IDs starting from 0.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.node_type_mapping = {}  # string -> int\n",
    "        self.relationship_type_mapping = {}  # string -> int\n",
    "        self.reverse_node_type_mapping = {}  # int -> string\n",
    "        self.reverse_relationship_type_mapping = {}  # int -> string\n",
    "        self.global_to_local_mapping = {}  # For reference: global_id -> (node_type, local_id)\n",
    "        \n",
    "    def load_and_prepare_primekg(self, nodes_csv_path: str, edges_csv_path: str):\n",
    "        \"\"\"\n",
    "        Load PrimeKG data and prepare it for bulk_load_heterogeneous_graph.\n",
    "        Each node type gets sequential IDs starting from 0.\n",
    "        \n",
    "        Args:\n",
    "            nodes_csv_path: Path to nodes CSV file\n",
    "            edges_csv_path: Path to edges CSV file\n",
    "            \n",
    "        Returns:\n",
    "            Tuple of (node_types_dict, edge_types_dict) ready for DGL loading\n",
    "        \"\"\"\n",
    "        print(\"Loading PrimeKG data...\")\n",
    "        start_time = time.time()\n",
    "        \n",
    "        # Load raw data\n",
    "        print(\"  Reading CSV files...\")\n",
    "        nodes_df = pd.read_csv(nodes_csv_path, low_memory=False)\n",
    "        edges_df = pd.read_csv(edges_csv_path, low_memory=False)\n",
    "        \n",
    "        print(f\"  Loaded {len(nodes_df):,} nodes and {len(edges_df):,} edges\")\n",
    "        \n",
    "        # Create type mappings\n",
    "        print(\"  Creating type mappings...\")\n",
    "        self._create_type_mappings(nodes_df, edges_df)\n",
    "        \n",
    "        # Prepare node data (sequential IDs starting from 0 for each type)\n",
    "        print(\"  Preparing node data...\")\n",
    "        node_types_dict = self._prepare_node_data(nodes_df)\n",
    "        \n",
    "        # Prepare edge data (using local IDs)\n",
    "        print(\"  Preparing edge data...\")\n",
    "        edge_types_dict = self._prepare_edge_data(edges_df, nodes_df)\n",
    "        \n",
    "        total_time = time.time() - start_time\n",
    "        print(f\"\\nData preparation completed in {total_time:.2f}s\")\n",
    "        \n",
    "        # Print summary\n",
    "        self._print_summary(node_types_dict, edge_types_dict)\n",
    "        \n",
    "        return node_types_dict, edge_types_dict, self.global_to_local_mapping\n",
    "    \n",
    "    def _create_type_mappings(self, nodes_df: pd.DataFrame, edges_df: pd.DataFrame):\n",
    "        \"\"\"Create mappings between string types and integer representations.\"\"\"\n",
    "        \n",
    "        # Node type mappings\n",
    "        unique_node_types = sorted(nodes_df['node_type'].unique())\n",
    "        self.node_type_mapping = {node_type: i for i, node_type in enumerate(unique_node_types)}\n",
    "        self.reverse_node_type_mapping = {i: node_type for node_type, i in self.node_type_mapping.items()}\n",
    "        \n",
    "        # Relationship type mappings\n",
    "        unique_rel_types = sorted(edges_df['relationship_type'].unique())\n",
    "        self.relationship_type_mapping = {rel_type: i for i, rel_type in enumerate(unique_rel_types)}\n",
    "        self.reverse_relationship_type_mapping = {i: rel_type for rel_type, i in self.relationship_type_mapping.items()}\n",
    "        \n",
    "        print(f\"    Found {len(unique_node_types)} node types: {unique_node_types}\")\n",
    "        print(f\"    Found {len(unique_rel_types)} relationship types: {unique_rel_types}\")\n",
    "    \n",
    "    def _prepare_node_data(self, nodes_df: pd.DataFrame) -> Dict[str, pd.DataFrame]:\n",
    "        \"\"\"\n",
    "        Group nodes by type and prepare DataFrames with sequential IDs starting from 0.\n",
    "        \n",
    "        Returns:\n",
    "            Dict mapping node_type_string -> DataFrame with columns ['node_id', 'name', 'metadata_source', 'node_type_id', 'original_global_id']\n",
    "        \"\"\"\n",
    "        node_types_dict = {}\n",
    "        \n",
    "        # Add numeric type ID to nodes\n",
    "        nodes_df_copy = nodes_df.copy()\n",
    "        nodes_df_copy['node_type_id'] = nodes_df_copy['node_type'].map(self.node_type_mapping)\n",
    "        \n",
    "        # Group by node type and assign sequential IDs starting from 0\n",
    "        for node_type_str, group_df in nodes_df_copy.groupby('node_type'):\n",
    "            # Sort by original ID for consistency\n",
    "            group_df = group_df.sort_values('id').reset_index(drop=True)\n",
    "            \n",
    "            # Create sequential IDs starting from 0\n",
    "            num_nodes = len(group_df)\n",
    "            \n",
    "            # Build global to local mapping for this node type\n",
    "            global_ids = group_df['id'].values\n",
    "            local_ids = np.arange(num_nodes)  # 0, 1, 2, ..., num_nodes-1\n",
    "            \n",
    "            # Store the mapping for edge processing\n",
    "            for local_id, global_id in zip(local_ids, global_ids):\n",
    "                self.global_to_local_mapping[global_id] = (node_type_str, local_id)\n",
    "            \n",
    "            # Prepare DataFrame for DGL\n",
    "            prepared_df = pd.DataFrame({\n",
    "                'node_id': local_ids,  # Sequential IDs starting from 0\n",
    "                'name': group_df['name'].values,\n",
    "                'metadata_source': group_df['metadata_source'].values,\n",
    "                'node_type_id': group_df['node_type_id'].values,\n",
    "                'original_global_id': global_ids  # Keep original for reference\n",
    "            })\n",
    "            \n",
    "            node_types_dict[node_type_str] = prepared_df\n",
    "            print(f\"    {node_type_str}: {num_nodes:,} nodes (IDs: 0 to {num_nodes-1})\")\n",
    "            \n",
    "        return node_types_dict\n",
    "    \n",
    "    def _prepare_edge_data(self, edges_df: pd.DataFrame, nodes_df: pd.DataFrame) -> Dict[Tuple[str, str, str], pd.DataFrame]:\n",
    "        \"\"\"\n",
    "        Prepare edge data grouped by (src_type, edge_type, dst_type) using local IDs.\n",
    "        \n",
    "        Returns:\n",
    "            Dict mapping (src_type, edge_type, dst_type) -> DataFrame with columns ['src', 'dst', 'relationship_type_id']\n",
    "        \"\"\"\n",
    "        # Create node ID to type mapping for fast lookup\n",
    "        node_id_to_type = dict(zip(nodes_df['id'], nodes_df['node_type']))\n",
    "        \n",
    "        # Add relationship type IDs\n",
    "        edges_df_copy = edges_df.copy()\n",
    "        edges_df_copy['relationship_type_id'] = edges_df_copy['relationship_type'].map(self.relationship_type_mapping)\n",
    "        \n",
    "        # Add source and target node types\n",
    "        edges_df_copy['src_type'] = edges_df_copy['source_id'].map(node_id_to_type)\n",
    "        edges_df_copy['dst_type'] = edges_df_copy['target_id'].map(node_id_to_type)\n",
    "        \n",
    "        # Filter out edges with unknown nodes\n",
    "        valid_mask = (edges_df_copy['src_type'].notna()) & (edges_df_copy['dst_type'].notna())\n",
    "        valid_edges = edges_df_copy[valid_mask]\n",
    "        \n",
    "        if len(valid_edges) < len(edges_df_copy):\n",
    "            print(f\"    Warning: Filtered out {len(edges_df_copy) - len(valid_edges)} edges with unknown nodes\")\n",
    "        \n",
    "        # Group by (src_type, relationship_type, dst_type)\n",
    "        edge_types_dict = {}\n",
    "        \n",
    "        for (src_type, rel_type, dst_type), group_df in valid_edges.groupby(['src_type', 'relationship_type', 'dst_type']):\n",
    "            print(f\"    Processing {src_type} --[{rel_type}]--> {dst_type}: {len(group_df):,} edges\")\n",
    "            \n",
    "            # VECTORIZED APPROACH - Much faster than loops\n",
    "            group_df_reset = group_df.reset_index(drop=True)\n",
    "            \n",
    "            # Create mapping functions for this specific edge type\n",
    "            src_type_mapping = {global_id: local_id for global_id, (nt, local_id) in self.global_to_local_mapping.items() if nt == src_type}\n",
    "            dst_type_mapping = {global_id: local_id for global_id, (nt, local_id) in self.global_to_local_mapping.items() if nt == dst_type}\n",
    "            \n",
    "            # Vectorized mapping using pandas map\n",
    "            group_df_reset['src_local'] = group_df_reset['source_id'].map(src_type_mapping)\n",
    "            group_df_reset['dst_local'] = group_df_reset['target_id'].map(dst_type_mapping)\n",
    "            \n",
    "            # Filter valid edges (both src and dst must be mapped)\n",
    "            valid_mask = (group_df_reset['src_local'].notna()) & (group_df_reset['dst_local'].notna())\n",
    "            valid_edges_df = group_df_reset[valid_mask]\n",
    "            \n",
    "            if len(valid_edges_df) == 0:\n",
    "                print(f\"      Warning: No valid edges found for {src_type}-{rel_type}->{dst_type}\")\n",
    "                continue\n",
    "            \n",
    "            # Create edge DataFrame with local node IDs\n",
    "            edge_df = pd.DataFrame({\n",
    "                'src': valid_edges_df['src_local'].astype(int).values,  # Local IDs (0-based for each node type)\n",
    "                'dst': valid_edges_df['dst_local'].astype(int).values,  # Local IDs (0-based for each node type)\n",
    "                'relationship_type_id': valid_edges_df['relationship_type_id'].values,\n",
    "                'original_src_id': valid_edges_df['source_id'].values,  # Keep original for reference\n",
    "                'original_dst_id': valid_edges_df['target_id'].values   # Keep original for reference\n",
    "            })\n",
    "            \n",
    "            edge_types_dict[(src_type, rel_type, dst_type)] = edge_df\n",
    "            print(f\"      Created {len(edge_df):,} valid edges\")\n",
    "            \n",
    "        return edge_types_dict\n",
    "    \n",
    "    def _print_summary(self, node_types_dict: Dict[str, pd.DataFrame], \n",
    "                      edge_types_dict: Dict[Tuple[str, str, str], pd.DataFrame]):\n",
    "        \"\"\"Print summary of prepared data.\"\"\"\n",
    "        print(\"\\n\" + \"=\"*60)\n",
    "        print(\"PRIMEKG DATA PREPARATION SUMMARY\")\n",
    "        print(\"=\"*60)\n",
    "        \n",
    "        print(\"\\nNode Type Mappings:\")\n",
    "        for str_type, int_type in self.node_type_mapping.items():\n",
    "            count = len(node_types_dict.get(str_type, []))\n",
    "            print(f\"  {int_type}: {str_type} ({count:,} nodes, IDs: 0 to {count-1})\")\n",
    "        \n",
    "        print(\"\\nRelationship Type Mappings:\")\n",
    "        for str_type, int_type in self.relationship_type_mapping.items():\n",
    "            print(f\"  {int_type}: {str_type}\")\n",
    "        \n",
    "        print(\"\\nPrepared Node Types:\")\n",
    "        total_nodes = 0\n",
    "        for node_type, df in node_types_dict.items():\n",
    "            min_id = df['node_id'].min()\n",
    "            max_id = df['node_id'].max()\n",
    "            print(f\"  {node_type}: {len(df):,} nodes (local IDs: {min_id} to {max_id})\")\n",
    "            total_nodes += len(df)\n",
    "        print(f\"  TOTAL: {total_nodes:,} nodes\")\n",
    "        \n",
    "        print(\"\\nPrepared Edge Types:\")\n",
    "        total_edges = 0\n",
    "        for (src_type, edge_type, dst_type), df in edge_types_dict.items():\n",
    "            print(f\"  {src_type} --[{edge_type}]--> {dst_type}: {len(df):,} edges\")\n",
    "            total_edges += len(df)\n",
    "        print(f\"  TOTAL: {total_edges:,} edges\")\n",
    "        \n",
    "        print(\"\\nData Format Verification:\")\n",
    "        for node_type, df in node_types_dict.items():\n",
    "            assert df['node_id'].min() == 0, f\"Node IDs for {node_type} don't start at 0!\"\n",
    "            assert df['node_id'].max() == len(df) - 1, f\"Node IDs for {node_type} are not sequential!\"\n",
    "            print(f\"  ✅ {node_type}: Sequential IDs 0 to {len(df)-1}\")\n",
    "        \n",
    "        print(\"=\"*60)\n",
    "    \n",
    "    def get_type_mappings(self):\n",
    "        \"\"\"Return the type mappings for reference.\"\"\"\n",
    "        return {\n",
    "            'node_types': self.node_type_mapping,\n",
    "            'relationship_types': self.relationship_type_mapping,\n",
    "            'reverse_node_types': self.reverse_node_type_mapping,\n",
    "            'reverse_relationship_types': self.reverse_relationship_type_mapping\n",
    "        }\n",
    "    \n",
    "    def get_global_to_local_mapping(self):\n",
    "        \"\"\"Return the global to local ID mapping for reference.\"\"\"\n",
    "        return self.global_to_local_mapping.copy()\n",
    "    \n",
    "    def global_id_to_local(self, global_id: int) -> Tuple[str, int]:\n",
    "        \"\"\"Convert a global node ID to (node_type, local_id).\"\"\"\n",
    "        if global_id in self.global_to_local_mapping:\n",
    "            return self.global_to_local_mapping[global_id]\n",
    "        else:\n",
    "            raise ValueError(f\"Global ID {global_id} not found in mapping\")\n",
    "    \n",
    "    def local_id_to_global(self, node_type: str, local_id: int) -> int:\n",
    "        \"\"\"Convert (node_type, local_id) to global node ID.\"\"\"\n",
    "        for global_id, (nt, lid) in self.global_to_local_mapping.items():\n",
    "            if nt == node_type and lid == local_id:\n",
    "                return global_id\n",
    "        raise ValueError(f\"Local ID ({node_type}, {local_id}) not found in mapping\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a3f43c74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading PrimeKG data...\n",
      "  Reading CSV files...\n",
      "  Loaded 129,375 nodes and 8,100,498 edges\n",
      "  Creating type mappings...\n",
      "    Found 10 node types: ['anatomy', 'biological_process', 'cellular_component', 'disease', 'drug', 'effectphenotype', 'exposure', 'geneprotein', 'molecular_function', 'pathway']\n",
      "    Found 30 relationship types: ['anatomy_anatomy', 'anatomy_protein_absent', 'anatomy_protein_present', 'bioprocess_bioprocess', 'bioprocess_protein', 'cellcomp_cellcomp', 'cellcomp_protein', 'contraindication', 'disease_disease', 'disease_phenotype_negative', 'disease_phenotype_positive', 'disease_protein', 'drug_drug', 'drug_effect', 'drug_protein', 'exposure_bioprocess', 'exposure_cellcomp', 'exposure_disease', 'exposure_exposure', 'exposure_molfunc', 'exposure_protein', 'indication', 'molfunc_molfunc', 'molfunc_protein', 'off-label use', 'pathway_pathway', 'pathway_protein', 'phenotype_phenotype', 'phenotype_protein', 'protein_protein']\n",
      "  Preparing node data...\n",
      "    anatomy: 14,035 nodes (IDs: 0 to 14034)\n",
      "    biological_process: 28,642 nodes (IDs: 0 to 28641)\n",
      "    cellular_component: 4,176 nodes (IDs: 0 to 4175)\n",
      "    disease: 17,080 nodes (IDs: 0 to 17079)\n",
      "    drug: 7,957 nodes (IDs: 0 to 7956)\n",
      "    effectphenotype: 15,311 nodes (IDs: 0 to 15310)\n",
      "    exposure: 818 nodes (IDs: 0 to 817)\n",
      "    geneprotein: 27,671 nodes (IDs: 0 to 27670)\n",
      "    molecular_function: 11,169 nodes (IDs: 0 to 11168)\n",
      "    pathway: 2,516 nodes (IDs: 0 to 2515)\n",
      "  Preparing edge data...\n",
      "    Processing anatomy --[anatomy_anatomy]--> anatomy: 28,064 edges\n",
      "      Created 28,064 valid edges\n",
      "    Processing anatomy --[anatomy_protein_absent]--> geneprotein: 19,887 edges\n",
      "      Created 19,887 valid edges\n",
      "    Processing anatomy --[anatomy_protein_present]--> geneprotein: 1,518,203 edges\n",
      "      Created 1,518,203 valid edges\n",
      "    Processing biological_process --[bioprocess_bioprocess]--> biological_process: 105,772 edges\n",
      "      Created 105,772 valid edges\n",
      "    Processing biological_process --[bioprocess_protein]--> geneprotein: 144,805 edges\n",
      "      Created 144,805 valid edges\n",
      "    Processing biological_process --[exposure_bioprocess]--> exposure: 1,625 edges\n",
      "      Created 1,625 valid edges\n",
      "    Processing cellular_component --[cellcomp_cellcomp]--> cellular_component: 9,690 edges\n",
      "      Created 9,690 valid edges\n",
      "    Processing cellular_component --[cellcomp_protein]--> geneprotein: 83,402 edges\n",
      "      Created 83,402 valid edges\n",
      "    Processing cellular_component --[exposure_cellcomp]--> exposure: 10 edges\n",
      "      Created 10 valid edges\n",
      "    Processing disease --[contraindication]--> drug: 30,675 edges\n",
      "      Created 30,675 valid edges\n",
      "    Processing disease --[disease_disease]--> disease: 64,388 edges\n",
      "      Created 64,388 valid edges\n",
      "    Processing disease --[disease_phenotype_negative]--> effectphenotype: 1,193 edges\n",
      "      Created 1,193 valid edges\n",
      "    Processing disease --[disease_phenotype_positive]--> effectphenotype: 150,317 edges\n",
      "      Created 150,317 valid edges\n",
      "    Processing disease --[disease_protein]--> geneprotein: 80,411 edges\n",
      "      Created 80,411 valid edges\n",
      "    Processing disease --[exposure_disease]--> exposure: 2,304 edges\n",
      "      Created 2,304 valid edges\n",
      "    Processing disease --[indication]--> drug: 9,388 edges\n",
      "      Created 9,388 valid edges\n",
      "    Processing disease --[off-label use]--> drug: 2,568 edges\n",
      "      Created 2,568 valid edges\n",
      "    Processing drug --[contraindication]--> disease: 30,675 edges\n",
      "      Created 30,675 valid edges\n",
      "    Processing drug --[drug_drug]--> drug: 2,672,628 edges\n",
      "      Created 2,672,628 valid edges\n",
      "    Processing drug --[drug_effect]--> effectphenotype: 64,784 edges\n",
      "      Created 64,784 valid edges\n",
      "    Processing drug --[drug_protein]--> geneprotein: 25,653 edges\n",
      "      Created 25,653 valid edges\n",
      "    Processing drug --[indication]--> disease: 9,388 edges\n",
      "      Created 9,388 valid edges\n",
      "    Processing drug --[off-label use]--> disease: 2,568 edges\n",
      "      Created 2,568 valid edges\n",
      "    Processing effectphenotype --[disease_phenotype_negative]--> disease: 1,193 edges\n",
      "      Created 1,193 valid edges\n",
      "    Processing effectphenotype --[disease_phenotype_positive]--> disease: 150,317 edges\n",
      "      Created 150,317 valid edges\n",
      "    Processing effectphenotype --[drug_effect]--> drug: 64,784 edges\n",
      "      Created 64,784 valid edges\n",
      "    Processing effectphenotype --[phenotype_phenotype]--> effectphenotype: 37,472 edges\n",
      "      Created 37,472 valid edges\n",
      "    Processing effectphenotype --[phenotype_protein]--> geneprotein: 3,330 edges\n",
      "      Created 3,330 valid edges\n",
      "    Processing exposure --[exposure_bioprocess]--> biological_process: 1,625 edges\n",
      "      Created 1,625 valid edges\n",
      "    Processing exposure --[exposure_cellcomp]--> cellular_component: 10 edges\n",
      "      Created 10 valid edges\n",
      "    Processing exposure --[exposure_disease]--> disease: 2,304 edges\n",
      "      Created 2,304 valid edges\n",
      "    Processing exposure --[exposure_exposure]--> exposure: 4,140 edges\n",
      "      Created 4,140 valid edges\n",
      "    Processing exposure --[exposure_molfunc]--> molecular_function: 45 edges\n",
      "      Created 45 valid edges\n",
      "    Processing exposure --[exposure_protein]--> geneprotein: 1,212 edges\n",
      "      Created 1,212 valid edges\n",
      "    Processing geneprotein --[anatomy_protein_absent]--> anatomy: 19,887 edges\n",
      "      Created 19,887 valid edges\n",
      "    Processing geneprotein --[anatomy_protein_present]--> anatomy: 1,518,203 edges\n",
      "      Created 1,518,203 valid edges\n",
      "    Processing geneprotein --[bioprocess_protein]--> biological_process: 144,805 edges\n",
      "      Created 144,805 valid edges\n",
      "    Processing geneprotein --[cellcomp_protein]--> cellular_component: 83,402 edges\n",
      "      Created 83,402 valid edges\n",
      "    Processing geneprotein --[disease_protein]--> disease: 80,411 edges\n",
      "      Created 80,411 valid edges\n",
      "    Processing geneprotein --[drug_protein]--> drug: 25,653 edges\n",
      "      Created 25,653 valid edges\n",
      "    Processing geneprotein --[exposure_protein]--> exposure: 1,212 edges\n",
      "      Created 1,212 valid edges\n",
      "    Processing geneprotein --[molfunc_protein]--> molecular_function: 69,530 edges\n",
      "      Created 69,530 valid edges\n",
      "    Processing geneprotein --[pathway_protein]--> pathway: 42,646 edges\n",
      "      Created 42,646 valid edges\n",
      "    Processing geneprotein --[phenotype_protein]--> effectphenotype: 3,330 edges\n",
      "      Created 3,330 valid edges\n",
      "    Processing geneprotein --[protein_protein]--> geneprotein: 642,150 edges\n",
      "      Created 642,150 valid edges\n",
      "    Processing molecular_function --[exposure_molfunc]--> exposure: 45 edges\n",
      "      Created 45 valid edges\n",
      "    Processing molecular_function --[molfunc_molfunc]--> molecular_function: 27,148 edges\n",
      "      Created 27,148 valid edges\n",
      "    Processing molecular_function --[molfunc_protein]--> geneprotein: 69,530 edges\n",
      "      Created 69,530 valid edges\n",
      "    Processing pathway --[pathway_pathway]--> pathway: 5,070 edges\n",
      "      Created 5,070 valid edges\n",
      "    Processing pathway --[pathway_protein]--> geneprotein: 42,646 edges\n",
      "      Created 42,646 valid edges\n",
      "\n",
      "Data preparation completed in 10.15s\n",
      "\n",
      "============================================================\n",
      "PRIMEKG DATA PREPARATION SUMMARY\n",
      "============================================================\n",
      "\n",
      "Node Type Mappings:\n",
      "  0: anatomy (14,035 nodes, IDs: 0 to 14034)\n",
      "  1: biological_process (28,642 nodes, IDs: 0 to 28641)\n",
      "  2: cellular_component (4,176 nodes, IDs: 0 to 4175)\n",
      "  3: disease (17,080 nodes, IDs: 0 to 17079)\n",
      "  4: drug (7,957 nodes, IDs: 0 to 7956)\n",
      "  5: effectphenotype (15,311 nodes, IDs: 0 to 15310)\n",
      "  6: exposure (818 nodes, IDs: 0 to 817)\n",
      "  7: geneprotein (27,671 nodes, IDs: 0 to 27670)\n",
      "  8: molecular_function (11,169 nodes, IDs: 0 to 11168)\n",
      "  9: pathway (2,516 nodes, IDs: 0 to 2515)\n",
      "\n",
      "Relationship Type Mappings:\n",
      "  0: anatomy_anatomy\n",
      "  1: anatomy_protein_absent\n",
      "  2: anatomy_protein_present\n",
      "  3: bioprocess_bioprocess\n",
      "  4: bioprocess_protein\n",
      "  5: cellcomp_cellcomp\n",
      "  6: cellcomp_protein\n",
      "  7: contraindication\n",
      "  8: disease_disease\n",
      "  9: disease_phenotype_negative\n",
      "  10: disease_phenotype_positive\n",
      "  11: disease_protein\n",
      "  12: drug_drug\n",
      "  13: drug_effect\n",
      "  14: drug_protein\n",
      "  15: exposure_bioprocess\n",
      "  16: exposure_cellcomp\n",
      "  17: exposure_disease\n",
      "  18: exposure_exposure\n",
      "  19: exposure_molfunc\n",
      "  20: exposure_protein\n",
      "  21: indication\n",
      "  22: molfunc_molfunc\n",
      "  23: molfunc_protein\n",
      "  24: off-label use\n",
      "  25: pathway_pathway\n",
      "  26: pathway_protein\n",
      "  27: phenotype_phenotype\n",
      "  28: phenotype_protein\n",
      "  29: protein_protein\n",
      "\n",
      "Prepared Node Types:\n",
      "  anatomy: 14,035 nodes (local IDs: 0 to 14034)\n",
      "  biological_process: 28,642 nodes (local IDs: 0 to 28641)\n",
      "  cellular_component: 4,176 nodes (local IDs: 0 to 4175)\n",
      "  disease: 17,080 nodes (local IDs: 0 to 17079)\n",
      "  drug: 7,957 nodes (local IDs: 0 to 7956)\n",
      "  effectphenotype: 15,311 nodes (local IDs: 0 to 15310)\n",
      "  exposure: 818 nodes (local IDs: 0 to 817)\n",
      "  geneprotein: 27,671 nodes (local IDs: 0 to 27670)\n",
      "  molecular_function: 11,169 nodes (local IDs: 0 to 11168)\n",
      "  pathway: 2,516 nodes (local IDs: 0 to 2515)\n",
      "  TOTAL: 129,375 nodes\n",
      "\n",
      "Prepared Edge Types:\n",
      "  anatomy --[anatomy_anatomy]--> anatomy: 28,064 edges\n",
      "  anatomy --[anatomy_protein_absent]--> geneprotein: 19,887 edges\n",
      "  anatomy --[anatomy_protein_present]--> geneprotein: 1,518,203 edges\n",
      "  biological_process --[bioprocess_bioprocess]--> biological_process: 105,772 edges\n",
      "  biological_process --[bioprocess_protein]--> geneprotein: 144,805 edges\n",
      "  biological_process --[exposure_bioprocess]--> exposure: 1,625 edges\n",
      "  cellular_component --[cellcomp_cellcomp]--> cellular_component: 9,690 edges\n",
      "  cellular_component --[cellcomp_protein]--> geneprotein: 83,402 edges\n",
      "  cellular_component --[exposure_cellcomp]--> exposure: 10 edges\n",
      "  disease --[contraindication]--> drug: 30,675 edges\n",
      "  disease --[disease_disease]--> disease: 64,388 edges\n",
      "  disease --[disease_phenotype_negative]--> effectphenotype: 1,193 edges\n",
      "  disease --[disease_phenotype_positive]--> effectphenotype: 150,317 edges\n",
      "  disease --[disease_protein]--> geneprotein: 80,411 edges\n",
      "  disease --[exposure_disease]--> exposure: 2,304 edges\n",
      "  disease --[indication]--> drug: 9,388 edges\n",
      "  disease --[off-label use]--> drug: 2,568 edges\n",
      "  drug --[contraindication]--> disease: 30,675 edges\n",
      "  drug --[drug_drug]--> drug: 2,672,628 edges\n",
      "  drug --[drug_effect]--> effectphenotype: 64,784 edges\n",
      "  drug --[drug_protein]--> geneprotein: 25,653 edges\n",
      "  drug --[indication]--> disease: 9,388 edges\n",
      "  drug --[off-label use]--> disease: 2,568 edges\n",
      "  effectphenotype --[disease_phenotype_negative]--> disease: 1,193 edges\n",
      "  effectphenotype --[disease_phenotype_positive]--> disease: 150,317 edges\n",
      "  effectphenotype --[drug_effect]--> drug: 64,784 edges\n",
      "  effectphenotype --[phenotype_phenotype]--> effectphenotype: 37,472 edges\n",
      "  effectphenotype --[phenotype_protein]--> geneprotein: 3,330 edges\n",
      "  exposure --[exposure_bioprocess]--> biological_process: 1,625 edges\n",
      "  exposure --[exposure_cellcomp]--> cellular_component: 10 edges\n",
      "  exposure --[exposure_disease]--> disease: 2,304 edges\n",
      "  exposure --[exposure_exposure]--> exposure: 4,140 edges\n",
      "  exposure --[exposure_molfunc]--> molecular_function: 45 edges\n",
      "  exposure --[exposure_protein]--> geneprotein: 1,212 edges\n",
      "  geneprotein --[anatomy_protein_absent]--> anatomy: 19,887 edges\n",
      "  geneprotein --[anatomy_protein_present]--> anatomy: 1,518,203 edges\n",
      "  geneprotein --[bioprocess_protein]--> biological_process: 144,805 edges\n",
      "  geneprotein --[cellcomp_protein]--> cellular_component: 83,402 edges\n",
      "  geneprotein --[disease_protein]--> disease: 80,411 edges\n",
      "  geneprotein --[drug_protein]--> drug: 25,653 edges\n",
      "  geneprotein --[exposure_protein]--> exposure: 1,212 edges\n",
      "  geneprotein --[molfunc_protein]--> molecular_function: 69,530 edges\n",
      "  geneprotein --[pathway_protein]--> pathway: 42,646 edges\n",
      "  geneprotein --[phenotype_protein]--> effectphenotype: 3,330 edges\n",
      "  geneprotein --[protein_protein]--> geneprotein: 642,150 edges\n",
      "  molecular_function --[exposure_molfunc]--> exposure: 45 edges\n",
      "  molecular_function --[molfunc_molfunc]--> molecular_function: 27,148 edges\n",
      "  molecular_function --[molfunc_protein]--> geneprotein: 69,530 edges\n",
      "  pathway --[pathway_pathway]--> pathway: 5,070 edges\n",
      "  pathway --[pathway_protein]--> geneprotein: 42,646 edges\n",
      "  TOTAL: 8,100,498 edges\n",
      "\n",
      "Data Format Verification:\n",
      "  ✅ anatomy: Sequential IDs 0 to 14034\n",
      "  ✅ biological_process: Sequential IDs 0 to 28641\n",
      "  ✅ cellular_component: Sequential IDs 0 to 4175\n",
      "  ✅ disease: Sequential IDs 0 to 17079\n",
      "  ✅ drug: Sequential IDs 0 to 7956\n",
      "  ✅ effectphenotype: Sequential IDs 0 to 15310\n",
      "  ✅ exposure: Sequential IDs 0 to 817\n",
      "  ✅ geneprotein: Sequential IDs 0 to 27670\n",
      "  ✅ molecular_function: Sequential IDs 0 to 11168\n",
      "  ✅ pathway: Sequential IDs 0 to 2515\n",
      "============================================================\n",
      "\n",
      "Type mappings created:\n",
      "Node types: {'anatomy': 0, 'biological_process': 1, 'cellular_component': 2, 'disease': 3, 'drug': 4, 'effectphenotype': 5, 'exposure': 6, 'geneprotein': 7, 'molecular_function': 8, 'pathway': 9}\n",
      "Relationship types: {'anatomy_anatomy': 0, 'anatomy_protein_absent': 1, 'anatomy_protein_present': 2, 'bioprocess_bioprocess': 3, 'bioprocess_protein': 4, 'cellcomp_cellcomp': 5, 'cellcomp_protein': 6, 'contraindication': 7, 'disease_disease': 8, 'disease_phenotype_negative': 9, 'disease_phenotype_positive': 10, 'disease_protein': 11, 'drug_drug': 12, 'drug_effect': 13, 'drug_protein': 14, 'exposure_bioprocess': 15, 'exposure_cellcomp': 16, 'exposure_disease': 17, 'exposure_exposure': 18, 'exposure_molfunc': 19, 'exposure_protein': 20, 'indication': 21, 'molfunc_molfunc': 22, 'molfunc_protein': 23, 'off-label use': 24, 'pathway_pathway': 25, 'pathway_protein': 26, 'phenotype_phenotype': 27, 'phenotype_protein': 28, 'protein_protein': 29}\n",
      "\n",
      "Data format verification:\n",
      "  anatomy: node_id range 0-14034\n",
      "  biological_process: node_id range 0-28641\n",
      "  cellular_component: node_id range 0-4175\n",
      "  disease: node_id range 0-17079\n",
      "  drug: node_id range 0-7956\n",
      "  effectphenotype: node_id range 0-15310\n",
      "  exposure: node_id range 0-817\n",
      "  geneprotein: node_id range 0-27670\n",
      "  molecular_function: node_id range 0-11168\n",
      "  pathway: node_id range 0-2515\n",
      "\n",
      "Ready to load into DGL!\n",
      "Use: analyzer.bulk_load_heterogeneous_graph(node_types_dict, edge_types_dict)\n",
      "Optimizing node mappings...\n",
      "Node mappings completed in 0.04s\n",
      "  Processing edge type anatomy-anatomy_anatomy->anatomy (28,064 edges)...\n",
      "    Mapped 28,064 valid edges\n",
      "  Processing edge type anatomy-anatomy_protein_absent->geneprotein (19,887 edges)...\n",
      "    Mapped 19,887 valid edges\n",
      "  Processing edge type anatomy-anatomy_protein_present->geneprotein (1,518,203 edges)...\n",
      "    Mapped 1,518,203 valid edges\n",
      "  Processing edge type biological_process-bioprocess_bioprocess->biological_process (105,772 edges)...\n",
      "    Mapped 105,772 valid edges\n",
      "  Processing edge type biological_process-bioprocess_protein->geneprotein (144,805 edges)...\n",
      "    Mapped 144,805 valid edges\n",
      "  Processing edge type biological_process-exposure_bioprocess->exposure (1,625 edges)...\n",
      "    Mapped 1,625 valid edges\n",
      "  Processing edge type cellular_component-cellcomp_cellcomp->cellular_component (9,690 edges)...\n",
      "    Mapped 9,690 valid edges\n",
      "  Processing edge type cellular_component-cellcomp_protein->geneprotein (83,402 edges)...\n",
      "    Mapped 83,402 valid edges\n",
      "  Processing edge type cellular_component-exposure_cellcomp->exposure (10 edges)...\n",
      "    Mapped 10 valid edges\n",
      "  Processing edge type disease-contraindication->drug (30,675 edges)...\n",
      "    Mapped 30,675 valid edges\n",
      "  Processing edge type disease-disease_disease->disease (64,388 edges)...\n",
      "    Mapped 64,388 valid edges\n",
      "  Processing edge type disease-disease_phenotype_negative->effectphenotype (1,193 edges)...\n",
      "    Mapped 1,193 valid edges\n",
      "  Processing edge type disease-disease_phenotype_positive->effectphenotype (150,317 edges)...\n",
      "    Mapped 150,317 valid edges\n",
      "  Processing edge type disease-disease_protein->geneprotein (80,411 edges)...\n",
      "    Mapped 80,411 valid edges\n",
      "  Processing edge type disease-exposure_disease->exposure (2,304 edges)...\n",
      "    Mapped 2,304 valid edges\n",
      "  Processing edge type disease-indication->drug (9,388 edges)...\n",
      "    Mapped 9,388 valid edges\n",
      "  Processing edge type disease-off-label use->drug (2,568 edges)...\n",
      "    Mapped 2,568 valid edges\n",
      "  Processing edge type drug-contraindication->disease (30,675 edges)...\n",
      "    Mapped 30,675 valid edges\n",
      "  Processing edge type drug-drug_drug->drug (2,672,628 edges)...\n",
      "    Mapped 2,672,628 valid edges\n",
      "  Processing edge type drug-drug_effect->effectphenotype (64,784 edges)...\n",
      "    Mapped 64,784 valid edges\n",
      "  Processing edge type drug-drug_protein->geneprotein (25,653 edges)...\n",
      "    Mapped 25,653 valid edges\n",
      "  Processing edge type drug-indication->disease (9,388 edges)...\n",
      "    Mapped 9,388 valid edges\n",
      "  Processing edge type drug-off-label use->disease (2,568 edges)...\n",
      "    Mapped 2,568 valid edges\n",
      "  Processing edge type effectphenotype-disease_phenotype_negative->disease (1,193 edges)...\n",
      "    Mapped 1,193 valid edges\n",
      "  Processing edge type effectphenotype-disease_phenotype_positive->disease (150,317 edges)...\n",
      "    Mapped 150,317 valid edges\n",
      "  Processing edge type effectphenotype-drug_effect->drug (64,784 edges)...\n",
      "    Mapped 64,784 valid edges\n",
      "  Processing edge type effectphenotype-phenotype_phenotype->effectphenotype (37,472 edges)...\n",
      "    Mapped 37,472 valid edges\n",
      "  Processing edge type effectphenotype-phenotype_protein->geneprotein (3,330 edges)...\n",
      "    Mapped 3,330 valid edges\n",
      "  Processing edge type exposure-exposure_bioprocess->biological_process (1,625 edges)...\n",
      "    Mapped 1,625 valid edges\n",
      "  Processing edge type exposure-exposure_cellcomp->cellular_component (10 edges)...\n",
      "    Mapped 10 valid edges\n",
      "  Processing edge type exposure-exposure_disease->disease (2,304 edges)...\n",
      "    Mapped 2,304 valid edges\n",
      "  Processing edge type exposure-exposure_exposure->exposure (4,140 edges)...\n",
      "    Mapped 4,140 valid edges\n",
      "  Processing edge type exposure-exposure_molfunc->molecular_function (45 edges)...\n",
      "    Mapped 45 valid edges\n",
      "  Processing edge type exposure-exposure_protein->geneprotein (1,212 edges)...\n",
      "    Mapped 1,212 valid edges\n",
      "  Processing edge type geneprotein-anatomy_protein_absent->anatomy (19,887 edges)...\n",
      "    Mapped 19,887 valid edges\n",
      "  Processing edge type geneprotein-anatomy_protein_present->anatomy (1,518,203 edges)...\n",
      "    Mapped 1,518,203 valid edges\n",
      "  Processing edge type geneprotein-bioprocess_protein->biological_process (144,805 edges)...\n",
      "    Mapped 144,805 valid edges\n",
      "  Processing edge type geneprotein-cellcomp_protein->cellular_component (83,402 edges)...\n",
      "    Mapped 83,402 valid edges\n",
      "  Processing edge type geneprotein-disease_protein->disease (80,411 edges)...\n",
      "    Mapped 80,411 valid edges\n",
      "  Processing edge type geneprotein-drug_protein->drug (25,653 edges)...\n",
      "    Mapped 25,653 valid edges\n",
      "  Processing edge type geneprotein-exposure_protein->exposure (1,212 edges)...\n",
      "    Mapped 1,212 valid edges\n",
      "  Processing edge type geneprotein-molfunc_protein->molecular_function (69,530 edges)...\n",
      "    Mapped 69,530 valid edges\n",
      "  Processing edge type geneprotein-pathway_protein->pathway (42,646 edges)...\n",
      "    Mapped 42,646 valid edges\n",
      "  Processing edge type geneprotein-phenotype_protein->effectphenotype (3,330 edges)...\n",
      "    Mapped 3,330 valid edges\n",
      "  Processing edge type geneprotein-protein_protein->geneprotein (642,150 edges)...\n",
      "    Mapped 642,150 valid edges\n",
      "  Processing edge type molecular_function-exposure_molfunc->exposure (45 edges)...\n",
      "    Mapped 45 valid edges\n",
      "  Processing edge type molecular_function-molfunc_molfunc->molecular_function (27,148 edges)...\n",
      "    Mapped 27,148 valid edges\n",
      "  Processing edge type molecular_function-molfunc_protein->geneprotein (69,530 edges)...\n",
      "    Mapped 69,530 valid edges\n",
      "  Processing edge type pathway-pathway_pathway->pathway (5,070 edges)...\n",
      "    Mapped 5,070 valid edges\n",
      "  Processing edge type pathway-pathway_protein->geneprotein (42,646 edges)...\n",
      "    Mapped 42,646 valid edges\n",
      "Edge processing completed in 2.06s\n",
      "Graph creation completed in 0.20s\n",
      "Feature addition completed in 2.05s\n",
      "\n",
      "Heterogeneous graph loaded successfully in 4.34s:\n",
      "  anatomy: 14,035 nodes\n",
      "  biological_process: 28,642 nodes\n",
      "  cellular_component: 4,176 nodes\n",
      "  disease: 17,080 nodes\n",
      "  drug: 7,957 nodes\n",
      "  effectphenotype: 15,311 nodes\n",
      "  exposure: 818 nodes\n",
      "  geneprotein: 27,671 nodes\n",
      "  molecular_function: 11,169 nodes\n",
      "  pathway: 2,516 nodes\n",
      "  ('anatomy', 'anatomy_anatomy', 'anatomy'): 28,064 edges\n",
      "  ('anatomy', 'anatomy_protein_absent', 'geneprotein'): 19,887 edges\n",
      "  ('anatomy', 'anatomy_protein_present', 'geneprotein'): 1,518,203 edges\n",
      "  ('biological_process', 'bioprocess_bioprocess', 'biological_process'): 105,772 edges\n",
      "  ('biological_process', 'bioprocess_protein', 'geneprotein'): 144,805 edges\n",
      "  ('biological_process', 'exposure_bioprocess', 'exposure'): 1,625 edges\n",
      "  ('cellular_component', 'cellcomp_cellcomp', 'cellular_component'): 9,690 edges\n",
      "  ('cellular_component', 'cellcomp_protein', 'geneprotein'): 83,402 edges\n",
      "  ('cellular_component', 'exposure_cellcomp', 'exposure'): 10 edges\n",
      "  ('disease', 'contraindication', 'drug'): 30,675 edges\n",
      "  ('disease', 'disease_disease', 'disease'): 64,388 edges\n",
      "  ('disease', 'disease_phenotype_negative', 'effectphenotype'): 1,193 edges\n",
      "  ('disease', 'disease_phenotype_positive', 'effectphenotype'): 150,317 edges\n",
      "  ('disease', 'disease_protein', 'geneprotein'): 80,411 edges\n",
      "  ('disease', 'exposure_disease', 'exposure'): 2,304 edges\n",
      "  ('disease', 'indication', 'drug'): 9,388 edges\n",
      "  ('disease', 'off-label use', 'drug'): 2,568 edges\n",
      "  ('drug', 'contraindication', 'disease'): 30,675 edges\n",
      "  ('drug', 'drug_drug', 'drug'): 2,672,628 edges\n",
      "  ('drug', 'drug_effect', 'effectphenotype'): 64,784 edges\n",
      "  ('drug', 'drug_protein', 'geneprotein'): 25,653 edges\n",
      "  ('drug', 'indication', 'disease'): 9,388 edges\n",
      "  ('drug', 'off-label use', 'disease'): 2,568 edges\n",
      "  ('effectphenotype', 'disease_phenotype_negative', 'disease'): 1,193 edges\n",
      "  ('effectphenotype', 'disease_phenotype_positive', 'disease'): 150,317 edges\n",
      "  ('effectphenotype', 'drug_effect', 'drug'): 64,784 edges\n",
      "  ('effectphenotype', 'phenotype_phenotype', 'effectphenotype'): 37,472 edges\n",
      "  ('effectphenotype', 'phenotype_protein', 'geneprotein'): 3,330 edges\n",
      "  ('exposure', 'exposure_bioprocess', 'biological_process'): 1,625 edges\n",
      "  ('exposure', 'exposure_cellcomp', 'cellular_component'): 10 edges\n",
      "  ('exposure', 'exposure_disease', 'disease'): 2,304 edges\n",
      "  ('exposure', 'exposure_exposure', 'exposure'): 4,140 edges\n",
      "  ('exposure', 'exposure_molfunc', 'molecular_function'): 45 edges\n",
      "  ('exposure', 'exposure_protein', 'geneprotein'): 1,212 edges\n",
      "  ('geneprotein', 'anatomy_protein_absent', 'anatomy'): 19,887 edges\n",
      "  ('geneprotein', 'anatomy_protein_present', 'anatomy'): 1,518,203 edges\n",
      "  ('geneprotein', 'bioprocess_protein', 'biological_process'): 144,805 edges\n",
      "  ('geneprotein', 'cellcomp_protein', 'cellular_component'): 83,402 edges\n",
      "  ('geneprotein', 'disease_protein', 'disease'): 80,411 edges\n",
      "  ('geneprotein', 'drug_protein', 'drug'): 25,653 edges\n",
      "  ('geneprotein', 'exposure_protein', 'exposure'): 1,212 edges\n",
      "  ('geneprotein', 'molfunc_protein', 'molecular_function'): 69,530 edges\n",
      "  ('geneprotein', 'pathway_protein', 'pathway'): 42,646 edges\n",
      "  ('geneprotein', 'phenotype_protein', 'effectphenotype'): 3,330 edges\n",
      "  ('geneprotein', 'protein_protein', 'geneprotein'): 642,150 edges\n",
      "  ('molecular_function', 'exposure_molfunc', 'exposure'): 45 edges\n",
      "  ('molecular_function', 'molfunc_molfunc', 'molecular_function'): 27,148 edges\n",
      "  ('molecular_function', 'molfunc_protein', 'geneprotein'): 69,530 edges\n",
      "  ('pathway', 'pathway_pathway', 'pathway'): 5,070 edges\n",
      "  ('pathway', 'pathway_protein', 'geneprotein'): 42,646 edges\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_384291/257438400.py:34: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  x = torch.load(\"/home/cc/PHD/dglframework/DeepKG/start_feats.pt\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading 768-dimensional features for 129375 global nodes...\n",
      "Feature loading completed in 0.843s\n",
      "Features organized by: ['anatomy', 'biological_process', 'cellular_component', 'disease', 'drug', 'effectphenotype', 'exposure', 'geneprotein', 'molecular_function', 'pathway']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'graph_type': 'heterogeneous',\n",
       " 'node_types': ['anatomy',\n",
       "  'biological_process',\n",
       "  'cellular_component',\n",
       "  'disease',\n",
       "  'drug',\n",
       "  'effectphenotype',\n",
       "  'exposure',\n",
       "  'geneprotein',\n",
       "  'molecular_function',\n",
       "  'pathway'],\n",
       " 'total_nodes': 129375,\n",
       " 'total_features_assigned': 129375,\n",
       " 'stats_by_type': {'anatomy': {'num_nodes': 14035,\n",
       "   'features_found': 14035,\n",
       "   'missing_global_ids': 0,\n",
       "   'feature_shape': (14035, 768)},\n",
       "  'biological_process': {'num_nodes': 28642,\n",
       "   'features_found': 28642,\n",
       "   'missing_global_ids': 0,\n",
       "   'feature_shape': (28642, 768)},\n",
       "  'cellular_component': {'num_nodes': 4176,\n",
       "   'features_found': 4176,\n",
       "   'missing_global_ids': 0,\n",
       "   'feature_shape': (4176, 768)},\n",
       "  'disease': {'num_nodes': 17080,\n",
       "   'features_found': 17080,\n",
       "   'missing_global_ids': 0,\n",
       "   'feature_shape': (17080, 768)},\n",
       "  'drug': {'num_nodes': 7957,\n",
       "   'features_found': 7957,\n",
       "   'missing_global_ids': 0,\n",
       "   'feature_shape': (7957, 768)},\n",
       "  'effectphenotype': {'num_nodes': 15311,\n",
       "   'features_found': 15311,\n",
       "   'missing_global_ids': 0,\n",
       "   'feature_shape': (15311, 768)},\n",
       "  'exposure': {'num_nodes': 818,\n",
       "   'features_found': 818,\n",
       "   'missing_global_ids': 0,\n",
       "   'feature_shape': (818, 768)},\n",
       "  'geneprotein': {'num_nodes': 27671,\n",
       "   'features_found': 27671,\n",
       "   'missing_global_ids': 0,\n",
       "   'feature_shape': (27671, 768)},\n",
       "  'molecular_function': {'num_nodes': 11169,\n",
       "   'features_found': 11169,\n",
       "   'missing_global_ids': 0,\n",
       "   'feature_shape': (11169, 768)},\n",
       "  'pathway': {'num_nodes': 2516,\n",
       "   'features_found': 2516,\n",
       "   'missing_global_ids': 0,\n",
       "   'feature_shape': (2516, 768)}},\n",
       " 'coverage_ratio': 1.0,\n",
       " 'loading_time': 0.8431506156921387,\n",
       " 'feature_name': 'x',\n",
       " 'feature_dim': 768}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from DeepGraphDB import DeepGraphDB\n",
    "import torch\n",
    "\n",
    "db = DeepGraphDB()\n",
    "# Initialize the loader\n",
    "loader = PrimeKGLoader()\n",
    "\n",
    "# Load and prepare data\n",
    "nodes_csv = \"data/nodes.csv\"  # Replace with your actual path\n",
    "edges_csv = \"data/edges.csv\"  # Replace with your actual path\n",
    "\n",
    "node_types_dict, edge_types_dict, mapping = loader.load_and_prepare_primekg(nodes_csv, edges_csv)\n",
    "\n",
    "    \n",
    "# Get type mappings for reference\n",
    "mappings = loader.get_type_mappings()\n",
    "print(\"\\nType mappings created:\")\n",
    "print(\"Node types:\", mappings['node_types'])\n",
    "print(\"Relationship types:\", mappings['relationship_types'])\n",
    "\n",
    "# Verify data format\n",
    "print(\"\\nData format verification:\")\n",
    "for node_type, df in node_types_dict.items():\n",
    "    print(f\"  {node_type}: node_id range {df['node_id'].min()}-{df['node_id'].max()}\")\n",
    "\n",
    "# Now you can use this data with your DGL graph analyzer\n",
    "print(\"\\nReady to load into DGL!\")\n",
    "print(\"Use: analyzer.bulk_load_heterogeneous_graph(node_types_dict, edge_types_dict)\")\n",
    "db.bulk_load_heterogeneous_graph(node_types_dict, edge_types_dict)\n",
    "db.set_mappings(loader.node_type_mapping, loader.relationship_type_mapping)\n",
    "db.set_global_to_local_mapping(mapping)\n",
    "\n",
    "# x = torch.rand(max(db.global_to_local_mapping.keys())+1, 256)\n",
    "x = torch.load(\"/home/cc/PHD/dglframework/DeepKG/start_feats.pt\")\n",
    "db.load_node_features_for_gnn(torch.tensor(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14af7c73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target edge types for prediction: [('cellular_component', 'cellcomp_cellcomp', 'cellular_component'), ('cellular_component', 'cellcomp_protein', 'geneprotein'), ('disease', 'disease_disease', 'disease'), ('disease', 'disease_protein', 'geneprotein'), ('geneprotein', 'cellcomp_protein', 'cellular_component'), ('geneprotein', 'disease_protein', 'disease'), ('geneprotein', 'molfunc_protein', 'molecular_function'), ('geneprotein', 'pathway_protein', 'pathway'), ('geneprotein', 'protein_protein', 'geneprotein'), ('molecular_function', 'molfunc_molfunc', 'molecular_function'), ('molecular_function', 'molfunc_protein', 'geneprotein'), ('pathway', 'pathway_pathway', 'pathway'), ('pathway', 'pathway_protein', 'geneprotein')]\n",
      "['anatomy', 'biological_process', 'cellular_component', 'disease', 'drug', 'effectphenotype', 'exposure', 'geneprotein', 'molecular_function', 'pathway']\n",
      "ModuleDict(\n",
      "  (anatomy): Linear(in_features=768, out_features=512, bias=True)\n",
      "  (biological_process): Linear(in_features=768, out_features=512, bias=True)\n",
      "  (cellular_component): Linear(in_features=768, out_features=512, bias=True)\n",
      "  (disease): Linear(in_features=768, out_features=512, bias=True)\n",
      "  (drug): Linear(in_features=768, out_features=512, bias=True)\n",
      "  (effectphenotype): Linear(in_features=768, out_features=512, bias=True)\n",
      "  (exposure): Linear(in_features=768, out_features=512, bias=True)\n",
      "  (geneprotein): Linear(in_features=768, out_features=512, bias=True)\n",
      "  (molecular_function): Linear(in_features=768, out_features=512, bias=True)\n",
      "  (pathway): Linear(in_features=768, out_features=512, bias=True)\n",
      ")\n",
      "Model created with 46086401 parameters\n",
      "\n",
      "Splitting edges into train/val/test sets...\n",
      "Edge type ('cellular_component', 'cellcomp_cellcomp', 'cellular_component'): 6298 train, 1453 val, 1939 test\n",
      "Edge type ('cellular_component', 'cellcomp_protein', 'geneprotein'): 54211 train, 12510 val, 16681 test\n",
      "Edge type ('disease', 'disease_disease', 'disease'): 41852 train, 9658 val, 12878 test\n",
      "Edge type ('disease', 'disease_protein', 'geneprotein'): 52267 train, 12061 val, 16083 test\n",
      "Edge type ('geneprotein', 'cellcomp_protein', 'cellular_component'): 54211 train, 12510 val, 16681 test\n",
      "Edge type ('geneprotein', 'disease_protein', 'disease'): 52267 train, 12061 val, 16083 test\n",
      "Edge type ('geneprotein', 'molfunc_protein', 'molecular_function'): 45194 train, 10429 val, 13907 test\n",
      "Edge type ('geneprotein', 'pathway_protein', 'pathway'): 27719 train, 6397 val, 8530 test\n",
      "Edge type ('geneprotein', 'protein_protein', 'geneprotein'): 417397 train, 96322 val, 128431 test\n",
      "Edge type ('molecular_function', 'molfunc_molfunc', 'molecular_function'): 17646 train, 4072 val, 5430 test\n",
      "Edge type ('molecular_function', 'molfunc_protein', 'geneprotein'): 45194 train, 10429 val, 13907 test\n",
      "Edge type ('pathway', 'pathway_pathway', 'pathway'): 3295 train, 760 val, 1015 test\n",
      "Edge type ('pathway', 'pathway_protein', 'geneprotein'): 27719 train, 6397 val, 8530 test\n",
      "Training graph created with 7645344 edges\n",
      "Starting training with proper train/val splits...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 10/100 [02:15<33:50, 22.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 009 | Loss: 8.8839\n",
      "  ('cellular_component', 'cellcomp_cellcomp', 'cellular_component') Val AUC: 0.6190, AP: 0.6012\n",
      "  ('cellular_component', 'cellcomp_protein', 'geneprotein') Val AUC: 0.7231, AP: 0.6723\n",
      "  ('disease', 'disease_disease', 'disease') Val AUC: 0.5230, AP: 0.5390\n",
      "  ('disease', 'disease_protein', 'geneprotein') Val AUC: 0.8658, AP: 0.8384\n",
      "  ('geneprotein', 'cellcomp_protein', 'cellular_component') Val AUC: 0.8912, AP: 0.8631\n",
      "  ('geneprotein', 'disease_protein', 'disease') Val AUC: 0.8863, AP: 0.8684\n",
      "  ('geneprotein', 'molfunc_protein', 'molecular_function') Val AUC: 0.8062, AP: 0.7129\n",
      "  ('geneprotein', 'pathway_protein', 'pathway') Val AUC: 0.5022, AP: 0.4941\n",
      "  ('geneprotein', 'protein_protein', 'geneprotein') Val AUC: 0.7374, AP: 0.6840\n",
      "  ('molecular_function', 'molfunc_molfunc', 'molecular_function') Val AUC: 0.6212, AP: 0.5955\n",
      "  ('molecular_function', 'molfunc_protein', 'geneprotein') Val AUC: 0.7286, AP: 0.6762\n",
      "  ('pathway', 'pathway_pathway', 'pathway') Val AUC: 0.6561, AP: 0.5963\n",
      "  ('pathway', 'pathway_protein', 'geneprotein') Val AUC: 0.8004, AP: 0.7403\n",
      "  Average Val AUC: 0.7200\n",
      "  Average Val AP: 0.6832\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 20/100 [04:33<30:18, 22.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 019 | Loss: 7.7778\n",
      "  ('cellular_component', 'cellcomp_cellcomp', 'cellular_component') Val AUC: 0.6655, AP: 0.6821\n",
      "  ('cellular_component', 'cellcomp_protein', 'geneprotein') Val AUC: 0.7312, AP: 0.6807\n",
      "  ('disease', 'disease_disease', 'disease') Val AUC: 0.5752, AP: 0.5700\n",
      "  ('disease', 'disease_protein', 'geneprotein') Val AUC: 0.8562, AP: 0.8333\n",
      "  ('geneprotein', 'cellcomp_protein', 'cellular_component') Val AUC: 0.9393, AP: 0.9383\n",
      "  ('geneprotein', 'disease_protein', 'disease') Val AUC: 0.9200, AP: 0.8959\n",
      "  ('geneprotein', 'molfunc_protein', 'molecular_function') Val AUC: 0.9226, AP: 0.9145\n",
      "  ('geneprotein', 'pathway_protein', 'pathway') Val AUC: 0.5690, AP: 0.5096\n",
      "  ('geneprotein', 'protein_protein', 'geneprotein') Val AUC: 0.7631, AP: 0.7200\n",
      "  ('molecular_function', 'molfunc_molfunc', 'molecular_function') Val AUC: 0.6415, AP: 0.6166\n",
      "  ('molecular_function', 'molfunc_protein', 'geneprotein') Val AUC: 0.7345, AP: 0.6814\n",
      "  ('pathway', 'pathway_pathway', 'pathway') Val AUC: 0.7821, AP: 0.7241\n",
      "  ('pathway', 'pathway_protein', 'geneprotein') Val AUC: 0.8344, AP: 0.7818\n",
      "  Average Val AUC: 0.7642\n",
      "  Average Val AP: 0.7345\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 30/100 [06:51<26:34, 22.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 029 | Loss: 7.1534\n",
      "  ('cellular_component', 'cellcomp_cellcomp', 'cellular_component') Val AUC: 0.7132, AP: 0.6978\n",
      "  ('cellular_component', 'cellcomp_protein', 'geneprotein') Val AUC: 0.7261, AP: 0.6782\n",
      "  ('disease', 'disease_disease', 'disease') Val AUC: 0.6251, AP: 0.6057\n",
      "  ('disease', 'disease_protein', 'geneprotein') Val AUC: 0.8541, AP: 0.8330\n",
      "  ('geneprotein', 'cellcomp_protein', 'cellular_component') Val AUC: 0.9465, AP: 0.9436\n",
      "  ('geneprotein', 'disease_protein', 'disease') Val AUC: 0.9349, AP: 0.9187\n",
      "  ('geneprotein', 'molfunc_protein', 'molecular_function') Val AUC: 0.9311, AP: 0.9214\n",
      "  ('geneprotein', 'pathway_protein', 'pathway') Val AUC: 0.6721, AP: 0.6240\n",
      "  ('geneprotein', 'protein_protein', 'geneprotein') Val AUC: 0.7801, AP: 0.7460\n",
      "  ('molecular_function', 'molfunc_molfunc', 'molecular_function') Val AUC: 0.7751, AP: 0.7765\n",
      "  ('molecular_function', 'molfunc_protein', 'geneprotein') Val AUC: 0.7351, AP: 0.6911\n",
      "  ('pathway', 'pathway_pathway', 'pathway') Val AUC: 0.8149, AP: 0.7816\n",
      "  ('pathway', 'pathway_protein', 'geneprotein') Val AUC: 0.8646, AP: 0.8181\n",
      "  Average Val AUC: 0.7979\n",
      "  Average Val AP: 0.7720\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 40/100 [09:09<22:46, 22.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 039 | Loss: 6.3943\n",
      "  ('cellular_component', 'cellcomp_cellcomp', 'cellular_component') Val AUC: 0.8041, AP: 0.8063\n",
      "  ('cellular_component', 'cellcomp_protein', 'geneprotein') Val AUC: 0.6986, AP: 0.6528\n",
      "  ('disease', 'disease_disease', 'disease') Val AUC: 0.7849, AP: 0.7508\n",
      "  ('disease', 'disease_protein', 'geneprotein') Val AUC: 0.7756, AP: 0.7494\n",
      "  ('geneprotein', 'cellcomp_protein', 'cellular_component') Val AUC: 0.9401, AP: 0.9390\n",
      "  ('geneprotein', 'disease_protein', 'disease') Val AUC: 0.9265, AP: 0.9186\n",
      "  ('geneprotein', 'molfunc_protein', 'molecular_function') Val AUC: 0.9396, AP: 0.9306\n",
      "  ('geneprotein', 'pathway_protein', 'pathway') Val AUC: 0.7683, AP: 0.7237\n",
      "  ('geneprotein', 'protein_protein', 'geneprotein') Val AUC: 0.7876, AP: 0.7540\n",
      "  ('molecular_function', 'molfunc_molfunc', 'molecular_function') Val AUC: 0.8813, AP: 0.8737\n",
      "  ('molecular_function', 'molfunc_protein', 'geneprotein') Val AUC: 0.7610, AP: 0.7161\n",
      "  ('pathway', 'pathway_pathway', 'pathway') Val AUC: 0.8514, AP: 0.8061\n",
      "  ('pathway', 'pathway_protein', 'geneprotein') Val AUC: 0.9049, AP: 0.8802\n",
      "  Average Val AUC: 0.8326\n",
      "  Average Val AP: 0.8078\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 50/100 [11:28<18:58, 22.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 049 | Loss: 6.1283\n",
      "  ('cellular_component', 'cellcomp_cellcomp', 'cellular_component') Val AUC: 0.8381, AP: 0.8231\n",
      "  ('cellular_component', 'cellcomp_protein', 'geneprotein') Val AUC: 0.7417, AP: 0.6981\n",
      "  ('disease', 'disease_disease', 'disease') Val AUC: 0.7815, AP: 0.7412\n",
      "  ('disease', 'disease_protein', 'geneprotein') Val AUC: 0.8735, AP: 0.8515\n",
      "  ('geneprotein', 'cellcomp_protein', 'cellular_component') Val AUC: 0.9505, AP: 0.9423\n",
      "  ('geneprotein', 'disease_protein', 'disease') Val AUC: 0.9439, AP: 0.9355\n",
      "  ('geneprotein', 'molfunc_protein', 'molecular_function') Val AUC: 0.9372, AP: 0.9202\n",
      "  ('geneprotein', 'pathway_protein', 'pathway') Val AUC: 0.7365, AP: 0.7019\n",
      "  ('geneprotein', 'protein_protein', 'geneprotein') Val AUC: 0.7691, AP: 0.7307\n",
      "  ('molecular_function', 'molfunc_molfunc', 'molecular_function') Val AUC: 0.9032, AP: 0.8869\n",
      "  ('molecular_function', 'molfunc_protein', 'geneprotein') Val AUC: 0.7829, AP: 0.7389\n",
      "  ('pathway', 'pathway_pathway', 'pathway') Val AUC: 0.8713, AP: 0.8424\n",
      "  ('pathway', 'pathway_protein', 'geneprotein') Val AUC: 0.9150, AP: 0.8826\n",
      "  Average Val AUC: 0.8496\n",
      "  Average Val AP: 0.8227\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 60/100 [13:45<15:10, 22.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 059 | Loss: 5.7609\n",
      "  ('cellular_component', 'cellcomp_cellcomp', 'cellular_component') Val AUC: 0.8924, AP: 0.8800\n",
      "  ('cellular_component', 'cellcomp_protein', 'geneprotein') Val AUC: 0.7719, AP: 0.7263\n",
      "  ('disease', 'disease_disease', 'disease') Val AUC: 0.8170, AP: 0.7764\n",
      "  ('disease', 'disease_protein', 'geneprotein') Val AUC: 0.8590, AP: 0.8336\n",
      "  ('geneprotein', 'cellcomp_protein', 'cellular_component') Val AUC: 0.9595, AP: 0.9547\n",
      "  ('geneprotein', 'disease_protein', 'disease') Val AUC: 0.9443, AP: 0.9350\n",
      "  ('geneprotein', 'molfunc_protein', 'molecular_function') Val AUC: 0.9581, AP: 0.9539\n",
      "  ('geneprotein', 'pathway_protein', 'pathway') Val AUC: 0.7941, AP: 0.7429\n",
      "  ('geneprotein', 'protein_protein', 'geneprotein') Val AUC: 0.7973, AP: 0.7641\n",
      "  ('molecular_function', 'molfunc_molfunc', 'molecular_function') Val AUC: 0.9314, AP: 0.9183\n",
      "  ('molecular_function', 'molfunc_protein', 'geneprotein') Val AUC: 0.8035, AP: 0.7538\n",
      "  ('pathway', 'pathway_pathway', 'pathway') Val AUC: 0.9150, AP: 0.8855\n",
      "  ('pathway', 'pathway_protein', 'geneprotein') Val AUC: 0.9162, AP: 0.8768\n",
      "  Average Val AUC: 0.8738\n",
      "  Average Val AP: 0.8463\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 70/100 [16:04<11:23, 22.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 069 | Loss: 5.2586\n",
      "  ('cellular_component', 'cellcomp_cellcomp', 'cellular_component') Val AUC: 0.9240, AP: 0.9127\n",
      "  ('cellular_component', 'cellcomp_protein', 'geneprotein') Val AUC: 0.8048, AP: 0.7570\n",
      "  ('disease', 'disease_disease', 'disease') Val AUC: 0.8733, AP: 0.8513\n",
      "  ('disease', 'disease_protein', 'geneprotein') Val AUC: 0.8762, AP: 0.8565\n",
      "  ('geneprotein', 'cellcomp_protein', 'cellular_component') Val AUC: 0.9636, AP: 0.9615\n",
      "  ('geneprotein', 'disease_protein', 'disease') Val AUC: 0.9491, AP: 0.9423\n",
      "  ('geneprotein', 'molfunc_protein', 'molecular_function') Val AUC: 0.9589, AP: 0.9495\n",
      "  ('geneprotein', 'pathway_protein', 'pathway') Val AUC: 0.8215, AP: 0.7591\n",
      "  ('geneprotein', 'protein_protein', 'geneprotein') Val AUC: 0.8028, AP: 0.7733\n",
      "  ('molecular_function', 'molfunc_molfunc', 'molecular_function') Val AUC: 0.9379, AP: 0.9278\n",
      "  ('molecular_function', 'molfunc_protein', 'geneprotein') Val AUC: 0.8222, AP: 0.7862\n",
      "  ('pathway', 'pathway_pathway', 'pathway') Val AUC: 0.9265, AP: 0.9021\n",
      "  ('pathway', 'pathway_protein', 'geneprotein') Val AUC: 0.9337, AP: 0.9054\n",
      "  Average Val AUC: 0.8919\n",
      "  Average Val AP: 0.8680\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|███████▌  | 76/100 [17:01<04:25, 11.06s/it]"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import dgl\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "from sklearn.model_selection import train_test_split\n",
    "from DeepGraphDB.gnns.heteroSAGEattn import AdvancedHeteroLinkPredictor, compute_loss\n",
    "\n",
    "in_feats = {ntype: x.shape[1] for ntype in db.graph.ntypes}\n",
    "# target_entities = ['drug', 'disease', 'geneprotein', 'effectphenotype']\n",
    "target_entities = ['geneprotein', 'disease', 'pathway', 'cellular_component', 'molecular_function']\n",
    "\n",
    "# Choose multiple edge types for prediction\n",
    "target_etypes = [ctype for ctype in db.graph.canonical_etypes if ctype[0] in target_entities and ctype[2] in target_entities]\n",
    "# target_etypes = [('disease', 'contraindication', 'drug'), ('disease', 'indication', 'drug'), ('drug', 'contraindication', 'disease'), ('drug', 'indication', 'disease')]\n",
    "\n",
    "print(f\"Target edge types for prediction: {target_etypes}\")\n",
    "\n",
    "hidden_feats = 512\n",
    "out_feats = 256\n",
    "\n",
    "model = AdvancedHeteroLinkPredictor(\n",
    "    node_types=db.graph.ntypes,  # All node types in the graph\n",
    "    edge_types=db.graph.etypes,  # All edge types for GNN layers\n",
    "    in_feats=in_feats,\n",
    "    hidden_feats=hidden_feats,\n",
    "    out_feats=out_feats,\n",
    "    num_layers=3,\n",
    "    use_attention=True,\n",
    "    predictor_type='mlp',\n",
    "    target_etypes=target_etypes  # Only target edge types for prediction\n",
    ")\n",
    "\n",
    "print(f\"Model created with {sum(p.numel() for p in model.parameters())} parameters\")\n",
    "\n",
    "embs = db.train_model(model, compute_loss, target_etypes, target_entities, 'cuda', num_epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc6334de",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ChromaVDB.chroma import ChromaFramework\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "vdb = ChromaFramework(persist_directory=\"./ChromaVDB/chroma_db\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5caa5fd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "records = vdb.list_records()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "267cc7be",
   "metadata": {},
   "outputs": [],
   "source": [
    "records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95df3284",
   "metadata": {},
   "outputs": [],
   "source": [
    "vdb.read_record(['377cd122-e832-4a8d-8bdf-e5ae3f471a93'], include_embeddings=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bd863cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5 min x 130k nodes\n",
    "BATCH_SIZE = 5000\n",
    "\n",
    "for entity in db.graph.ntypes:\n",
    "    embeddings_tensor = embs[entity].cpu()\n",
    "    total = embeddings_tensor.shape[0]\n",
    "    names = db.node_data[entity]['name'].tolist()\n",
    "    \n",
    "    for i in tqdm(range(0, total, BATCH_SIZE)):\n",
    "        end = i + BATCH_SIZE\n",
    "\n",
    "        batch_ids = [db.reverse_node_mapping[(entity, j)] for j in range(i, min(end, total))]\n",
    "        batch_embeddings = {\"graph\": embeddings_tensor[i:min(end, total)]}\n",
    "        batch_entities = [entity] * len(batch_embeddings[\"graph\"])\n",
    "        batch_names = names[i:min(end, total)]\n",
    "        batch_metadata = [{} for _ in range(len(batch_embeddings[\"graph\"]))]\n",
    "        batch_docs = [\"\" for _ in range(len(batch_embeddings[\"graph\"]))]\n",
    "\n",
    "        vdb.create_records(\n",
    "            global_ids=batch_ids,\n",
    "            names=batch_names,\n",
    "            entities=batch_entities,\n",
    "            metadatas=batch_metadata,\n",
    "            documents=batch_docs,\n",
    "            embeddings=batch_embeddings\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ca929d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "records = vdb.list_records()\n",
    "len(records)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c517bc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "embs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edc53940",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import seaborn as sns\n",
    "\n",
    "def visualize_embeddings_tsne(entity_embeddings_dict, \n",
    "                             perplexity=35, \n",
    "                             n_iter=1000, \n",
    "                             random_state=42,\n",
    "                             figsize=(12, 8),\n",
    "                             show_individual_labels=False,\n",
    "                             font_size=8):\n",
    "    \"\"\"\n",
    "    Create a t-SNE visualization of embeddings where each entity type has multiple embeddings.\n",
    "    \n",
    "    Parameters:\n",
    "    entity_embeddings_dict (dict): Dictionary with entity types as keys and lists of embeddings as values\n",
    "                                  e.g., {\"person\": [[emb1], [emb2], ...], \"location\": [[emb1], [emb2], ...]}\n",
    "    perplexity (int): t-SNE perplexity parameter\n",
    "    n_iter (int): Number of iterations for t-SNE\n",
    "    random_state (int): Random state for reproducibility\n",
    "    figsize (tuple): Figure size for the plot\n",
    "    show_individual_labels (bool): Whether to show individual point labels (can be cluttered)\n",
    "    font_size (int): Font size for labels\n",
    "    \"\"\"\n",
    "    \n",
    "    # Flatten the data and keep track of entity types\n",
    "    all_embeddings = []\n",
    "    entity_labels = []\n",
    "    entity_types = []\n",
    "    \n",
    "    for entity_type, embeddings_list in entity_embeddings_dict.items():\n",
    "        embeddings_array = np.array(embeddings_list.cpu())\n",
    "        \n",
    "        # Handle different input formats\n",
    "        if embeddings_array.ndim == 1:\n",
    "            embeddings_array = embeddings_array.reshape(1, -1)\n",
    "        \n",
    "        print(f\"{entity_type}: {len(embeddings_array)} embeddings of dimension {embeddings_array.shape[1]}\")\n",
    "        \n",
    "        for i, embedding in enumerate(embeddings_array):\n",
    "            all_embeddings.append(embedding)\n",
    "            entity_labels.append(f\"{entity_type}_{i}\")\n",
    "            entity_types.append(entity_type)\n",
    "    \n",
    "    all_embeddings = np.array(all_embeddings)\n",
    "    total_points = len(all_embeddings)\n",
    "    \n",
    "    print(f\"\\nTotal: {total_points} embeddings across {len(entity_embeddings_dict)} entity types\")\n",
    "    \n",
    "    # Standardize the embeddings\n",
    "    scaler = StandardScaler()\n",
    "    embeddings_scaled = scaler.fit_transform(all_embeddings)\n",
    "    \n",
    "    # Apply t-SNE\n",
    "    print(\"Applying t-SNE...\")\n",
    "    tsne = TSNE(n_components=2, \n",
    "                perplexity=min(perplexity, total_points-1),\n",
    "                n_iter=n_iter, \n",
    "                random_state=random_state,\n",
    "                verbose=1)\n",
    "    \n",
    "    embeddings_2d = tsne.fit_transform(embeddings_scaled)\n",
    "    \n",
    "    # Create the visualization\n",
    "    plt.figure(figsize=figsize)\n",
    "    \n",
    "    # Create a color palette for entity types\n",
    "    unique_entity_types = list(entity_embeddings_dict.keys())\n",
    "    colors = sns.color_palette(\"husl\", len(unique_entity_types))\n",
    "    color_map = dict(zip(unique_entity_types, colors))\n",
    "    \n",
    "    # Plot points colored by entity type\n",
    "    for entity_type in unique_entity_types:\n",
    "        # Get indices for this entity type\n",
    "        indices = [i for i, et in enumerate(entity_types) if et == entity_type]\n",
    "        x_coords = embeddings_2d[indices, 0]\n",
    "        y_coords = embeddings_2d[indices, 1]\n",
    "        \n",
    "        plt.scatter(x_coords, y_coords, \n",
    "                   c=[color_map[entity_type]], \n",
    "                   label=f\"{entity_type} ({len(indices)})\",\n",
    "                   s=60, alpha=0.7, edgecolors='black', linewidth=0.5)\n",
    "        \n",
    "        # Optionally add individual labels\n",
    "        if show_individual_labels:\n",
    "            for i, idx in enumerate(indices):\n",
    "                plt.annotate(f\"{entity_type}_{i}\", \n",
    "                            (embeddings_2d[idx, 0], embeddings_2d[idx, 1]),\n",
    "                            xytext=(2, 2), textcoords='offset points',\n",
    "                            fontsize=font_size, alpha=0.8)\n",
    "    \n",
    "    plt.title(f't-SNE Visualization of Entity Embeddings\\n({total_points} total embeddings, {len(unique_entity_types)} entity types)', \n",
    "              fontsize=14, fontweight='bold')\n",
    "    plt.xlabel('t-SNE Component 1', fontsize=12)\n",
    "    plt.ylabel('t-SNE Component 2', fontsize=12)\n",
    "    plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Remove ticks for cleaner look\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    return embeddings_2d, entity_labels, entity_types\n",
    "\n",
    "def analyze_clusters(embeddings_2d, entity_types, entity_embeddings_dict):\n",
    "    \"\"\"\n",
    "    Analyze the clustering quality and provide statistics.\n",
    "    \"\"\"\n",
    "    from collections import Counter\n",
    "    import pandas as pd\n",
    "    \n",
    "    # Create DataFrame for analysis\n",
    "    df = pd.DataFrame({\n",
    "        'x': embeddings_2d[:, 0],\n",
    "        'y': embeddings_2d[:, 1],\n",
    "        'entity_type': entity_types\n",
    "    })\n",
    "    \n",
    "    print(\"\\n=== Cluster Analysis ===\")\n",
    "    print(\"Entity type distribution:\")\n",
    "    type_counts = Counter(entity_types)\n",
    "    for entity_type, count in type_counts.items():\n",
    "        print(f\"  {entity_type}: {count} embeddings\")\n",
    "    \n",
    "    # Calculate centroids for each entity type\n",
    "    print(\"\\nEntity type centroids:\")\n",
    "    for entity_type in entity_embeddings_dict.keys():\n",
    "        mask = df['entity_type'] == entity_type\n",
    "        centroid_x = df[mask]['x'].mean()\n",
    "        centroid_y = df[mask]['y'].mean()\n",
    "        print(f\"  {entity_type}: ({centroid_x:.3f}, {centroid_y:.3f})\")\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Example usage with sample data\n",
    "if __name__ == \"__main__\":\n",
    "    # Example: Create sample embeddings dictionary with multiple embeddings per entity type\n",
    "    np.random.seed(42)\n",
    "    \n",
    "    print(\"Running example with sample data...\")\n",
    "    print(\"Replace 'sample_entities' with your actual entity_embeddings_dict\")\n",
    "    \n",
    "    # Visualize the embeddings\n",
    "    tsne_coords, labels, types = visualize_embeddings_tsne(\n",
    "        embs,\n",
    "        perplexity=35,  # Lower perplexity for smaller dataset\n",
    "        figsize=(12, 8),\n",
    "        show_individual_labels=False  # Set to True if you want individual point labels\n",
    "    )\n",
    "    \n",
    "    # Analyze clusters\n",
    "    # cluster_df = analyze_clusters(tsne_coords, types, sample_entities)\n",
    "    \n",
    "    # Optional: Save the plot\n",
    "    # plt.savefig('entity_embeddings_tsne.png', dpi=300, bbox_inches='tight')\n",
    "\n",
    "# Usage for your actual data:\n",
    "# your_entity_embeddings = {\n",
    "#     \"person\": [\n",
    "#         [0.1, 0.2, 0.3, ...],  # embedding 1 for person\n",
    "#         [0.4, 0.5, 0.6, ...],  # embedding 2 for person\n",
    "#         [0.7, 0.8, 0.9, ...],  # embedding 3 for person\n",
    "#         # ... more person embeddings\n",
    "#     ],\n",
    "#     \"location\": [\n",
    "#         [0.2, 0.3, 0.4, ...],  # embedding 1 for location\n",
    "#         [0.5, 0.6, 0.7, ...],  # embedding 2 for location\n",
    "#         # ... more location embeddings\n",
    "#     ],\n",
    "#     # ... more entity types\n",
    "# }\n",
    "# \n",
    "# tsne_coords, labels, types = visualize_embeddings_tsne(your_entity_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efc43ee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import seaborn as sns\n",
    "from collections import Counter\n",
    "import time\n",
    "import warnings\n",
    "\n",
    "def sample_embeddings_stratified(entity_embeddings_dict, max_total_samples=10000, min_per_type=50):\n",
    "    \"\"\"\n",
    "    Stratified sampling to handle large datasets while maintaining entity type proportions.\n",
    "    \n",
    "    Parameters:\n",
    "    entity_embeddings_dict (dict): Original embeddings dictionary\n",
    "    max_total_samples (int): Maximum total number of samples to keep\n",
    "    min_per_type (int): Minimum samples per entity type\n",
    "    \n",
    "    Returns:\n",
    "    dict: Sampled embeddings dictionary\n",
    "    \"\"\"\n",
    "    total_embeddings = sum(len(embs) for embs in entity_embeddings_dict.values())\n",
    "    \n",
    "    if total_embeddings <= max_total_samples:\n",
    "        print(f\"Dataset size ({total_embeddings}) is within limit. No sampling needed.\")\n",
    "        return entity_embeddings_dict\n",
    "    \n",
    "    print(f\"Large dataset detected ({total_embeddings:,} embeddings)\")\n",
    "    print(f\"Applying stratified sampling to reduce to ~{max_total_samples:,} samples...\")\n",
    "    \n",
    "    # Calculate proportional samples per entity type\n",
    "    sampled_dict = {}\n",
    "    remaining_budget = max_total_samples\n",
    "    entity_types = list(entity_embeddings_dict.keys())\n",
    "    \n",
    "    # First, ensure minimum samples per type\n",
    "    for entity_type in entity_types:\n",
    "        available = len(entity_embeddings_dict[entity_type])\n",
    "        min_samples = min(min_per_type, available, remaining_budget)\n",
    "        \n",
    "        if available > 0 and remaining_budget > 0:\n",
    "            indices = np.random.choice(available, min_samples, replace=False)\n",
    "            sampled_dict[entity_type] = [entity_embeddings_dict[entity_type][i] for i in indices]\n",
    "            remaining_budget -= min_samples\n",
    "        else:\n",
    "            sampled_dict[entity_type] = []\n",
    "    \n",
    "    # Distribute remaining budget proportionally\n",
    "    if remaining_budget > 0:\n",
    "        total_remaining = sum(len(entity_embeddings_dict[et]) - len(sampled_dict[et]) \n",
    "                            for et in entity_types)\n",
    "        \n",
    "        for entity_type in entity_types:\n",
    "            available_remaining = len(entity_embeddings_dict[entity_type]) - len(sampled_dict[entity_type])\n",
    "            if available_remaining > 0 and total_remaining > 0:\n",
    "                proportion = available_remaining / total_remaining\n",
    "                additional_samples = min(int(remaining_budget * proportion), available_remaining)\n",
    "                \n",
    "                if additional_samples > 0:\n",
    "                    # Get indices not already sampled\n",
    "                    already_sampled = set(np.random.choice(len(entity_embeddings_dict[entity_type]), \n",
    "                                                         len(sampled_dict[entity_type]), replace=False))\n",
    "                    available_indices = [i for i in range(len(entity_embeddings_dict[entity_type])) \n",
    "                                       if i not in already_sampled]\n",
    "                    \n",
    "                    additional_indices = np.random.choice(len(available_indices), \n",
    "                                                        additional_samples, replace=False)\n",
    "                    additional_embeddings = [entity_embeddings_dict[entity_type][available_indices[i]] \n",
    "                                           for i in additional_indices]\n",
    "                    sampled_dict[entity_type].extend(additional_embeddings)\n",
    "    \n",
    "    # Print sampling summary\n",
    "    print(\"\\nSampling summary:\")\n",
    "    total_sampled = 0\n",
    "    for entity_type in entity_types:\n",
    "        original_count = len(entity_embeddings_dict[entity_type])\n",
    "        sampled_count = len(sampled_dict[entity_type])\n",
    "        total_sampled += sampled_count\n",
    "        print(f\"  {entity_type}: {sampled_count:,} / {original_count:,} \"\n",
    "              f\"({100*sampled_count/original_count:.1f}%)\")\n",
    "    \n",
    "    print(f\"\\nTotal: {total_sampled:,} / {total_embeddings:,} \"\n",
    "          f\"({100*total_sampled/total_embeddings:.1f}%)\")\n",
    "    \n",
    "    return sampled_dict\n",
    "\n",
    "def visualize_embeddings_tsne(entity_embeddings_dict, \n",
    "                             perplexity=30, \n",
    "                             n_iter=1000, \n",
    "                             random_state=42,\n",
    "                             figsize=(12, 8),\n",
    "                             show_individual_labels=False,\n",
    "                             font_size=8,\n",
    "                             max_samples=10000,\n",
    "                             use_sampling=True,\n",
    "                             use_umap=False,\n",
    "                             alpha=0.6,\n",
    "                             point_size=20):\n",
    "    \"\"\"\n",
    "    Create a t-SNE/UMAP visualization optimized for large datasets.\n",
    "    \n",
    "    Parameters:\n",
    "    entity_embeddings_dict (dict): Dictionary with entity types as keys and lists of embeddings as values\n",
    "    perplexity (int): t-SNE perplexity parameter\n",
    "    n_iter (int): Number of iterations for t-SNE\n",
    "    random_state (int): Random state for reproducibility\n",
    "    figsize (tuple): Figure size for the plot\n",
    "    show_individual_labels (bool): Whether to show individual point labels\n",
    "    font_size (int): Font size for labels\n",
    "    max_samples (int): Maximum number of samples to use (for performance)\n",
    "    use_sampling (bool): Whether to apply sampling for large datasets\n",
    "    use_umap (bool): Use UMAP instead of t-SNE (faster for large datasets)\n",
    "    alpha (float): Point transparency (useful for dense plots)\n",
    "    point_size (int): Size of points in scatter plot\n",
    "    \"\"\"\n",
    "    \n",
    "    # Handle large datasets with sampling\n",
    "    if use_sampling:\n",
    "        entity_embeddings_dict = sample_embeddings_stratified(\n",
    "            entity_embeddings_dict, max_total_samples=max_samples\n",
    "        )\n",
    "    \n",
    "    # Flatten the data and keep track of entity types\n",
    "    all_embeddings = []\n",
    "    entity_labels = []\n",
    "    entity_types = []\n",
    "    \n",
    "    for entity_type, embeddings_list in entity_embeddings_dict.items():\n",
    "        embeddings_array = np.array(embeddings_list)\n",
    "        \n",
    "        # Handle different input formats\n",
    "        if embeddings_array.ndim == 1:\n",
    "            embeddings_array = embeddings_array.reshape(1, -1)\n",
    "        \n",
    "        print(f\"{entity_type}: {len(embeddings_array)} embeddings of dimension {embeddings_array.shape[1]}\")\n",
    "        \n",
    "        for i, embedding in enumerate(embeddings_array):\n",
    "            all_embeddings.append(embedding)\n",
    "            entity_labels.append(f\"{entity_type}_{i}\")\n",
    "            entity_types.append(entity_type)\n",
    "    \n",
    "    all_embeddings = np.array(all_embeddings)\n",
    "    total_points = len(all_embeddings)\n",
    "    \n",
    "    print(f\"\\nProcessing {total_points:,} embeddings across {len(entity_embeddings_dict)} entity types\")\n",
    "    \n",
    "    # Memory usage warning\n",
    "    memory_estimate_gb = (total_points ** 2 * 8) / (1024**3)  # Rough estimate for t-SNE\n",
    "    if memory_estimate_gb > 4 and not use_umap:\n",
    "        print(f\"⚠️  Warning: Estimated memory usage: {memory_estimate_gb:.1f}GB\")\n",
    "        print(\"Consider using UMAP (set use_umap=True) or reducing max_samples\")\n",
    "    \n",
    "    # Standardize the embeddings\n",
    "    print(\"Standardizing embeddings...\")\n",
    "    scaler = StandardScaler()\n",
    "    embeddings_scaled = scaler.fit_transform(all_embeddings)\n",
    "    \n",
    "    # Apply dimensionality reduction\n",
    "    start_time = time.time()\n",
    "    \n",
    "    if use_umap:\n",
    "        try:\n",
    "            import umap\n",
    "            print(\"Applying UMAP...\")\n",
    "            reducer = umap.UMAP(n_components=2, \n",
    "                              n_neighbors=min(15, total_points-1),\n",
    "                              random_state=random_state,\n",
    "                              verbose=True)\n",
    "            embeddings_2d = reducer.fit_transform(embeddings_scaled)\n",
    "            method_name = \"UMAP\"\n",
    "        except ImportError:\n",
    "            print(\"UMAP not installed. Install with: pip install umap-learn\")\n",
    "            print(\"Falling back to t-SNE...\")\n",
    "            use_umap = False\n",
    "    \n",
    "    if not use_umap:\n",
    "        print(\"Applying t-SNE...\")\n",
    "        tsne = TSNE(n_components=2, \n",
    "                    perplexity=min(perplexity, total_points-1),\n",
    "                    n_iter=n_iter, \n",
    "                    random_state=random_state,\n",
    "                    verbose=1,\n",
    "                    n_jobs=-1)  # Use all CPU cores\n",
    "        embeddings_2d = tsne.fit_transform(embeddings_scaled)\n",
    "        method_name = \"t-SNE\"\n",
    "    \n",
    "    duration = time.time() - start_time\n",
    "    print(f\"{method_name} completed in {duration:.1f} seconds\")\n",
    "    \n",
    "    # Create the visualization\n",
    "    plt.figure(figsize=figsize)\n",
    "    \n",
    "    # Create a color palette for entity types\n",
    "    unique_entity_types = list(set(entity_types))\n",
    "    colors = sns.color_palette(\"husl\", len(unique_entity_types))\n",
    "    color_map = dict(zip(unique_entity_types, colors))\n",
    "    \n",
    "    # Plot points colored by entity type\n",
    "    for entity_type in unique_entity_types:\n",
    "        # Get indices for this entity type\n",
    "        indices = [i for i, et in enumerate(entity_types) if et == entity_type]\n",
    "        x_coords = embeddings_2d[indices, 0]\n",
    "        y_coords = embeddings_2d[indices, 1]\n",
    "        \n",
    "        plt.scatter(x_coords, y_coords, \n",
    "                   c=[color_map[entity_type]], \n",
    "                   label=f\"{entity_type} ({len(indices):,})\",\n",
    "                   s=point_size, alpha=alpha, \n",
    "                   edgecolors='black', linewidth=0.3)\n",
    "        \n",
    "        # Only add individual labels for small datasets\n",
    "        if show_individual_labels and total_points < 1000:\n",
    "            for i, idx in enumerate(indices[:50]):  # Limit to first 50 per type\n",
    "                plt.annotate(f\"{entity_type}_{i}\", \n",
    "                            (embeddings_2d[idx, 0], embeddings_2d[idx, 1]),\n",
    "                            xytext=(2, 2), textcoords='offset points',\n",
    "                            fontsize=font_size, alpha=0.8)\n",
    "        elif show_individual_labels:\n",
    "            print(\"Too many points for individual labels. Skipping labels.\")\n",
    "    \n",
    "    sample_note = f\" (sampled)\" if use_sampling and total_points < sum(len(embs) for embs in entity_embeddings_dict.values()) else \"\"\n",
    "    \n",
    "    plt.title(f'{method_name} Visualization of Entity Embeddings{sample_note}\\n'\n",
    "              f'({total_points:,} embeddings, {len(unique_entity_types)} entity types)', \n",
    "              fontsize=14, fontweight='bold')\n",
    "    plt.xlabel(f'{method_name} Component 1', fontsize=12)\n",
    "    plt.ylabel(f'{method_name} Component 2', fontsize=12)\n",
    "    plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Remove ticks for cleaner look\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    return embeddings_2d, entity_labels, entity_types\n",
    "\n",
    "def create_density_plot(entity_embeddings_dict, max_samples=50000, figsize=(15, 10)):\n",
    "    \"\"\"\n",
    "    Create a density plot for very large datasets where individual points would be too cluttered.\n",
    "    \"\"\"\n",
    "    import scipy.stats as stats\n",
    "    \n",
    "    # Sample data if too large\n",
    "    if sum(len(embs) for embs in entity_embeddings_dict.values()) > max_samples:\n",
    "        entity_embeddings_dict = sample_embeddings_stratified(entity_embeddings_dict, max_samples)\n",
    "    \n",
    "    # Get 2D coordinates (using UMAP for speed)\n",
    "    coords_2d, labels, types = visualize_embeddings_tsne(\n",
    "        entity_embeddings_dict, use_umap=True, figsize=(1, 1)\n",
    "    )\n",
    "    plt.close()  # Close the scatter plot\n",
    "    \n",
    "    # Create density plots\n",
    "    fig, axes = plt.subplots(2, 2, figsize=figsize)\n",
    "    \n",
    "    # Overall density plot\n",
    "    ax = axes[0, 0]\n",
    "    ax.hexbin(coords_2d[:, 0], coords_2d[:, 1], gridsize=50, cmap='Blues')\n",
    "    ax.set_title('Overall Density')\n",
    "    ax.set_xlabel('Component 1')\n",
    "    ax.set_ylabel('Component 2')\n",
    "    \n",
    "    # Density by entity type\n",
    "    unique_types = list(set(types))\n",
    "    colors = sns.color_palette(\"husl\", len(unique_types))\n",
    "    \n",
    "    ax = axes[0, 1]\n",
    "    for i, entity_type in enumerate(unique_types):\n",
    "        mask = np.array(types) == entity_type\n",
    "        if np.sum(mask) > 10:  # Only plot if enough points\n",
    "            ax.scatter(coords_2d[mask, 0], coords_2d[mask, 1], \n",
    "                      c=[colors[i]], alpha=0.3, s=1, label=entity_type)\n",
    "    ax.set_title('All Entity Types')\n",
    "    ax.legend()\n",
    "    \n",
    "    # Individual density plots for top 2 entity types\n",
    "    type_counts = Counter(types)\n",
    "    top_types = [t[0] for t in type_counts.most_common(2)]\n",
    "    \n",
    "    for i, entity_type in enumerate(top_types):\n",
    "        ax = axes[1, i]\n",
    "        mask = np.array(types) == entity_type\n",
    "        ax.hexbin(coords_2d[mask, 0], coords_2d[mask, 1], \n",
    "                 gridsize=30, cmap='Reds')\n",
    "        ax.set_title(f'{entity_type} Density ({np.sum(mask):,} points)')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Performance comparison function\n",
    "def compare_methods(entity_embeddings_dict, sample_size=5000):\n",
    "    \"\"\"\n",
    "    Compare t-SNE vs UMAP performance on a sample of your data.\n",
    "    \"\"\"\n",
    "    # Sample data for fair comparison\n",
    "    sampled_data = sample_embeddings_stratified(entity_embeddings_dict, sample_size)\n",
    "    \n",
    "    print(f\"\\nPerformance comparison on {sample_size:,} samples:\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    # Test t-SNE\n",
    "    start_time = time.time()\n",
    "    try:\n",
    "        coords_tsne, _, _ = visualize_embeddings_tsne(\n",
    "            sampled_data, use_sampling=False, use_umap=False, figsize=(8, 6)\n",
    "        )\n",
    "        tsne_time = time.time() - start_time\n",
    "        print(f\"t-SNE: {tsne_time:.1f} seconds\")\n",
    "        plt.close()\n",
    "    except Exception as e:\n",
    "        print(f\"t-SNE failed: {e}\")\n",
    "        tsne_time = float('inf')\n",
    "    \n",
    "    # Test UMAP\n",
    "    start_time = time.time()\n",
    "    try:\n",
    "        coords_umap, _, _ = visualize_embeddings_tsne(\n",
    "            sampled_data, use_sampling=False, use_umap=True, figsize=(8, 6)\n",
    "        )\n",
    "        umap_time = time.time() - start_time\n",
    "        print(f\"UMAP: {umap_time:.1f} seconds\")\n",
    "        plt.close()\n",
    "    except Exception as e:\n",
    "        print(f\"UMAP failed: {e}\")\n",
    "        umap_time = float('inf')\n",
    "    \n",
    "    if tsne_time < float('inf') and umap_time < float('inf'):\n",
    "        speedup = tsne_time / umap_time\n",
    "        print(f\"\\nUMAP is {speedup:.1f}x faster than t-SNE\")\n",
    "        \n",
    "        if sample_size < 50000:\n",
    "            full_tsne_estimate = tsne_time * (sum(len(embs) for embs in entity_embeddings_dict.values()) / sample_size) ** 1.5\n",
    "            full_umap_estimate = umap_time * (sum(len(embs) for embs in entity_embeddings_dict.values()) / sample_size)\n",
    "            print(f\"Estimated time for full dataset:\")\n",
    "            print(f\"  t-SNE: {full_tsne_estimate/60:.1f} minutes\")\n",
    "            print(f\"  UMAP: {full_umap_estimate/60:.1f} minutes\")\n",
    "\n",
    "# Example usage optimized for large datasets\n",
    "if __name__ == \"__main__\":\n",
    "    # Example with larger sample data\n",
    "    np.random.seed(42)\n",
    "    \n",
    "    # Simulate larger dataset\n",
    "    def create_large_sample_data(n_types=5, embeddings_per_type_range=(1000, 5000), embedding_dim=128):\n",
    "        \"\"\"Create sample data that mimics a large real dataset.\"\"\"\n",
    "        large_entities = {}\n",
    "        \n",
    "        for i in range(n_types):\n",
    "            entity_type = f\"entity_type_{i}\"\n",
    "            n_embeddings = np.random.randint(*embeddings_per_type_range)\n",
    "            \n",
    "            # Create embeddings with some structure\n",
    "            base_vector = np.random.randn(embedding_dim) * 2\n",
    "            embeddings = []\n",
    "            \n",
    "            for _ in range(n_embeddings):\n",
    "                # Add noise to base vector to create similar but distinct embeddings\n",
    "                embedding = base_vector + np.random.randn(embedding_dim) * 0.5\n",
    "                embeddings.append(embedding.tolist())\n",
    "            \n",
    "            large_entities[entity_type] = embeddings\n",
    "        \n",
    "        return large_entities\n",
    "    \n",
    "    total_embeddings = sum(len(emb) for emb in embs.values())\n",
    "    print(f\"Created sample dataset with {total_embeddings:,} embeddings\")\n",
    "    \n",
    "    # Demonstrate different visualization strategies\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"STRATEGY 1: Sampled t-SNE (recommended for exploration)\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    coords, labels, types = visualize_embeddings_tsne(\n",
    "        embs,\n",
    "        max_samples=25000,  # Reduce for performance\n",
    "        use_sampling=True,\n",
    "        use_umap=False,\n",
    "        perplexity=30,\n",
    "        alpha=0.7,\n",
    "        point_size=15\n",
    "    )\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"STRATEGY 2: UMAP (faster, good for large datasets)\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    coords_umap, labels_umap, types_umap = visualize_embeddings_tsne(\n",
    "        embs,\n",
    "        max_samples=35000,  # Can handle more with UMAP\n",
    "        use_sampling=True,\n",
    "        use_umap=True,\n",
    "        alpha=0.7,\n",
    "        point_size=15\n",
    "    )\n",
    "\n",
    "# Usage recommendations for your large dataset:\n",
    "\"\"\"\n",
    "For 100k+ embeddings, recommended approaches:\n",
    "\n",
    "1. SAMPLED t-SNE (best for initial exploration):\n",
    "   visualize_embeddings_tsne(your_data, max_samples=10000, use_umap=False)\n",
    "\n",
    "2. UMAP (faster, can handle more points):\n",
    "   visualize_embeddings_tsne(your_data, max_samples=25000, use_umap=True)\n",
    "\n",
    "3. DENSITY PLOTS (for very large datasets):\n",
    "   create_density_plot(your_data, max_samples=50000)\n",
    "\n",
    "4. PERFORMANCE COMPARISON:\n",
    "   compare_methods(your_data, sample_size=5000)\n",
    "\n",
    "Example with your data:\n",
    "your_entity_embeddings = {\n",
    "    \"person\": [[emb1], [emb2], ...],     # thousands of person embeddings\n",
    "    \"location\": [[emb1], [emb2], ...],   # thousands of location embeddings\n",
    "    # ... more entity types\n",
    "}\n",
    "\n",
    "# For quick exploration (recommended starting point):\n",
    "visualize_embeddings_tsne(your_entity_embeddings, max_samples=15000, use_umap=True)\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
