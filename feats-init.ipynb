{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a605e366",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from typing import Dict, Tuple\n",
    "from collections import defaultdict\n",
    "import time\n",
    "\n",
    "class PrimeKGLoader:\n",
    "    \"\"\"\n",
    "    Prepares PrimeKG data for efficient loading into DGL heterogeneous graphs.\n",
    "    Each node type gets sequential IDs starting from 0.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.node_type_mapping = {}  # string -> int\n",
    "        self.relationship_type_mapping = {}  # string -> int\n",
    "        self.reverse_node_type_mapping = {}  # int -> string\n",
    "        self.reverse_relationship_type_mapping = {}  # int -> string\n",
    "        self.global_to_local_mapping = {}  # For reference: global_id -> (node_type, local_id)\n",
    "        \n",
    "    def load_and_prepare_primekg(self, nodes_csv_path: str, edges_csv_path: str):\n",
    "        \"\"\"\n",
    "        Load PrimeKG data and prepare it for bulk_load_heterogeneous_graph.\n",
    "        Each node type gets sequential IDs starting from 0.\n",
    "        \n",
    "        Args:\n",
    "            nodes_csv_path: Path to nodes CSV file\n",
    "            edges_csv_path: Path to edges CSV file\n",
    "            \n",
    "        Returns:\n",
    "            Tuple of (node_types_dict, edge_types_dict) ready for DGL loading\n",
    "        \"\"\"\n",
    "        print(\"Loading PrimeKG data...\")\n",
    "        start_time = time.time()\n",
    "        \n",
    "        # Load raw data\n",
    "        print(\"  Reading CSV files...\")\n",
    "        nodes_df = pd.read_csv(nodes_csv_path, low_memory=False)\n",
    "        edges_df = pd.read_csv(edges_csv_path, low_memory=False)\n",
    "        \n",
    "        print(f\"  Loaded {len(nodes_df):,} nodes and {len(edges_df):,} edges\")\n",
    "        \n",
    "        # Create type mappings\n",
    "        print(\"  Creating type mappings...\")\n",
    "        self._create_type_mappings(nodes_df, edges_df)\n",
    "        \n",
    "        # Prepare node data (sequential IDs starting from 0 for each type)\n",
    "        print(\"  Preparing node data...\")\n",
    "        node_types_dict = self._prepare_node_data(nodes_df)\n",
    "        \n",
    "        # Prepare edge data (using local IDs)\n",
    "        print(\"  Preparing edge data...\")\n",
    "        edge_types_dict = self._prepare_edge_data(edges_df, nodes_df)\n",
    "        \n",
    "        total_time = time.time() - start_time\n",
    "        print(f\"\\nData preparation completed in {total_time:.2f}s\")\n",
    "        \n",
    "        # Print summary\n",
    "        self._print_summary(node_types_dict, edge_types_dict)\n",
    "        \n",
    "        return node_types_dict, edge_types_dict, self.global_to_local_mapping\n",
    "    \n",
    "    def _create_type_mappings(self, nodes_df: pd.DataFrame, edges_df: pd.DataFrame):\n",
    "        \"\"\"Create mappings between string types and integer representations.\"\"\"\n",
    "        \n",
    "        # Node type mappings\n",
    "        unique_node_types = sorted(nodes_df['node_type'].unique())\n",
    "        self.node_type_mapping = {node_type: i for i, node_type in enumerate(unique_node_types)}\n",
    "        self.reverse_node_type_mapping = {i: node_type for node_type, i in self.node_type_mapping.items()}\n",
    "        \n",
    "        # Relationship type mappings\n",
    "        unique_rel_types = sorted(edges_df['relationship_type'].unique())\n",
    "        self.relationship_type_mapping = {rel_type: i for i, rel_type in enumerate(unique_rel_types)}\n",
    "        self.reverse_relationship_type_mapping = {i: rel_type for rel_type, i in self.relationship_type_mapping.items()}\n",
    "        \n",
    "        print(f\"    Found {len(unique_node_types)} node types: {unique_node_types}\")\n",
    "        print(f\"    Found {len(unique_rel_types)} relationship types: {unique_rel_types}\")\n",
    "    \n",
    "    def _prepare_node_data(self, nodes_df: pd.DataFrame) -> Dict[str, pd.DataFrame]:\n",
    "        \"\"\"\n",
    "        Group nodes by type and prepare DataFrames with sequential IDs starting from 0.\n",
    "        \n",
    "        Returns:\n",
    "            Dict mapping node_type_string -> DataFrame with columns ['node_id', 'name', 'metadata_source', 'node_type_id', 'original_global_id']\n",
    "        \"\"\"\n",
    "        node_types_dict = {}\n",
    "        \n",
    "        # Add numeric type ID to nodes\n",
    "        nodes_df_copy = nodes_df.copy()\n",
    "        nodes_df_copy['node_type_id'] = nodes_df_copy['node_type'].map(self.node_type_mapping)\n",
    "        \n",
    "        # Group by node type and assign sequential IDs starting from 0\n",
    "        for node_type_str, group_df in nodes_df_copy.groupby('node_type'):\n",
    "            # Sort by original ID for consistency\n",
    "            group_df = group_df.sort_values('id').reset_index(drop=True)\n",
    "            \n",
    "            # Create sequential IDs starting from 0\n",
    "            num_nodes = len(group_df)\n",
    "            \n",
    "            # Build global to local mapping for this node type\n",
    "            global_ids = group_df['id'].values\n",
    "            local_ids = np.arange(num_nodes)  # 0, 1, 2, ..., num_nodes-1\n",
    "            \n",
    "            # Store the mapping for edge processing\n",
    "            for local_id, global_id in zip(local_ids, global_ids):\n",
    "                self.global_to_local_mapping[global_id] = (node_type_str, local_id)\n",
    "            \n",
    "            # Prepare DataFrame for DGL\n",
    "            prepared_df = pd.DataFrame({\n",
    "                'node_id': local_ids,  # Sequential IDs starting from 0\n",
    "                'name': group_df['name'].values,\n",
    "                'metadata_source': group_df['metadata_source'].values,\n",
    "                'node_type_id': group_df['node_type_id'].values,\n",
    "                'original_global_id': global_ids  # Keep original for reference\n",
    "            })\n",
    "            \n",
    "            node_types_dict[node_type_str] = prepared_df\n",
    "            print(f\"    {node_type_str}: {num_nodes:,} nodes (IDs: 0 to {num_nodes-1})\")\n",
    "            \n",
    "        return node_types_dict\n",
    "    \n",
    "    def _prepare_edge_data(self, edges_df: pd.DataFrame, nodes_df: pd.DataFrame) -> Dict[Tuple[str, str, str], pd.DataFrame]:\n",
    "        \"\"\"\n",
    "        Prepare edge data grouped by (src_type, edge_type, dst_type) using local IDs.\n",
    "        \n",
    "        Returns:\n",
    "            Dict mapping (src_type, edge_type, dst_type) -> DataFrame with columns ['src', 'dst', 'relationship_type_id']\n",
    "        \"\"\"\n",
    "        # Create node ID to type mapping for fast lookup\n",
    "        node_id_to_type = dict(zip(nodes_df['id'], nodes_df['node_type']))\n",
    "        \n",
    "        # Add relationship type IDs\n",
    "        edges_df_copy = edges_df.copy()\n",
    "        edges_df_copy['relationship_type_id'] = edges_df_copy['relationship_type'].map(self.relationship_type_mapping)\n",
    "        \n",
    "        # Add source and target node types\n",
    "        edges_df_copy['src_type'] = edges_df_copy['source_id'].map(node_id_to_type)\n",
    "        edges_df_copy['dst_type'] = edges_df_copy['target_id'].map(node_id_to_type)\n",
    "        \n",
    "        # Filter out edges with unknown nodes\n",
    "        valid_mask = (edges_df_copy['src_type'].notna()) & (edges_df_copy['dst_type'].notna())\n",
    "        valid_edges = edges_df_copy[valid_mask]\n",
    "        \n",
    "        if len(valid_edges) < len(edges_df_copy):\n",
    "            print(f\"    Warning: Filtered out {len(edges_df_copy) - len(valid_edges)} edges with unknown nodes\")\n",
    "        \n",
    "        # Group by (src_type, relationship_type, dst_type)\n",
    "        edge_types_dict = {}\n",
    "        \n",
    "        for (src_type, rel_type, dst_type), group_df in valid_edges.groupby(['src_type', 'relationship_type', 'dst_type']):\n",
    "            print(f\"    Processing {src_type} --[{rel_type}]--> {dst_type}: {len(group_df):,} edges\")\n",
    "            \n",
    "            # VECTORIZED APPROACH - Much faster than loops\n",
    "            group_df_reset = group_df.reset_index(drop=True)\n",
    "            \n",
    "            # Create mapping functions for this specific edge type\n",
    "            src_type_mapping = {global_id: local_id for global_id, (nt, local_id) in self.global_to_local_mapping.items() if nt == src_type}\n",
    "            dst_type_mapping = {global_id: local_id for global_id, (nt, local_id) in self.global_to_local_mapping.items() if nt == dst_type}\n",
    "            \n",
    "            # Vectorized mapping using pandas map\n",
    "            group_df_reset['src_local'] = group_df_reset['source_id'].map(src_type_mapping)\n",
    "            group_df_reset['dst_local'] = group_df_reset['target_id'].map(dst_type_mapping)\n",
    "            \n",
    "            # Filter valid edges (both src and dst must be mapped)\n",
    "            valid_mask = (group_df_reset['src_local'].notna()) & (group_df_reset['dst_local'].notna())\n",
    "            valid_edges_df = group_df_reset[valid_mask]\n",
    "            \n",
    "            if len(valid_edges_df) == 0:\n",
    "                print(f\"      Warning: No valid edges found for {src_type}-{rel_type}->{dst_type}\")\n",
    "                continue\n",
    "            \n",
    "            # Create edge DataFrame with local node IDs\n",
    "            edge_df = pd.DataFrame({\n",
    "                'src': valid_edges_df['src_local'].astype(int).values,  # Local IDs (0-based for each node type)\n",
    "                'dst': valid_edges_df['dst_local'].astype(int).values,  # Local IDs (0-based for each node type)\n",
    "                'relationship_type_id': valid_edges_df['relationship_type_id'].values,\n",
    "                'original_src_id': valid_edges_df['source_id'].values,  # Keep original for reference\n",
    "                'original_dst_id': valid_edges_df['target_id'].values   # Keep original for reference\n",
    "            })\n",
    "            \n",
    "            edge_types_dict[(src_type, rel_type, dst_type)] = edge_df\n",
    "            print(f\"      Created {len(edge_df):,} valid edges\")\n",
    "            \n",
    "        return edge_types_dict\n",
    "    \n",
    "    def _print_summary(self, node_types_dict: Dict[str, pd.DataFrame], \n",
    "                      edge_types_dict: Dict[Tuple[str, str, str], pd.DataFrame]):\n",
    "        \"\"\"Print summary of prepared data.\"\"\"\n",
    "        print(\"\\n\" + \"=\"*60)\n",
    "        print(\"PRIMEKG DATA PREPARATION SUMMARY\")\n",
    "        print(\"=\"*60)\n",
    "        \n",
    "        print(\"\\nNode Type Mappings:\")\n",
    "        for str_type, int_type in self.node_type_mapping.items():\n",
    "            count = len(node_types_dict.get(str_type, []))\n",
    "            print(f\"  {int_type}: {str_type} ({count:,} nodes, IDs: 0 to {count-1})\")\n",
    "        \n",
    "        print(\"\\nRelationship Type Mappings:\")\n",
    "        for str_type, int_type in self.relationship_type_mapping.items():\n",
    "            print(f\"  {int_type}: {str_type}\")\n",
    "        \n",
    "        print(\"\\nPrepared Node Types:\")\n",
    "        total_nodes = 0\n",
    "        for node_type, df in node_types_dict.items():\n",
    "            min_id = df['node_id'].min()\n",
    "            max_id = df['node_id'].max()\n",
    "            print(f\"  {node_type}: {len(df):,} nodes (local IDs: {min_id} to {max_id})\")\n",
    "            total_nodes += len(df)\n",
    "        print(f\"  TOTAL: {total_nodes:,} nodes\")\n",
    "        \n",
    "        print(\"\\nPrepared Edge Types:\")\n",
    "        total_edges = 0\n",
    "        for (src_type, edge_type, dst_type), df in edge_types_dict.items():\n",
    "            print(f\"  {src_type} --[{edge_type}]--> {dst_type}: {len(df):,} edges\")\n",
    "            total_edges += len(df)\n",
    "        print(f\"  TOTAL: {total_edges:,} edges\")\n",
    "        \n",
    "        print(\"\\nData Format Verification:\")\n",
    "        for node_type, df in node_types_dict.items():\n",
    "            assert df['node_id'].min() == 0, f\"Node IDs for {node_type} don't start at 0!\"\n",
    "            assert df['node_id'].max() == len(df) - 1, f\"Node IDs for {node_type} are not sequential!\"\n",
    "            print(f\"  ✅ {node_type}: Sequential IDs 0 to {len(df)-1}\")\n",
    "        \n",
    "        print(\"=\"*60)\n",
    "    \n",
    "    def get_type_mappings(self):\n",
    "        \"\"\"Return the type mappings for reference.\"\"\"\n",
    "        return {\n",
    "            'node_types': self.node_type_mapping,\n",
    "            'relationship_types': self.relationship_type_mapping,\n",
    "            'reverse_node_types': self.reverse_node_type_mapping,\n",
    "            'reverse_relationship_types': self.reverse_relationship_type_mapping\n",
    "        }\n",
    "    \n",
    "    def get_global_to_local_mapping(self):\n",
    "        \"\"\"Return the global to local ID mapping for reference.\"\"\"\n",
    "        return self.global_to_local_mapping.copy()\n",
    "    \n",
    "    def global_id_to_local(self, global_id: int) -> Tuple[str, int]:\n",
    "        \"\"\"Convert a global node ID to (node_type, local_id).\"\"\"\n",
    "        if global_id in self.global_to_local_mapping:\n",
    "            return self.global_to_local_mapping[global_id]\n",
    "        else:\n",
    "            raise ValueError(f\"Global ID {global_id} not found in mapping\")\n",
    "    \n",
    "    def local_id_to_global(self, node_type: str, local_id: int) -> int:\n",
    "        \"\"\"Convert (node_type, local_id) to global node ID.\"\"\"\n",
    "        for global_id, (nt, lid) in self.global_to_local_mapping.items():\n",
    "            if nt == node_type and lid == local_id:\n",
    "                return global_id\n",
    "        raise ValueError(f\"Local ID ({node_type}, {local_id}) not found in mapping\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3163b08a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from DeepGraphDB import DeepGraphDB\n",
    "import torch\n",
    "\n",
    "db = DeepGraphDB()\n",
    "# Initialize the loader\n",
    "loader = PrimeKGLoader()\n",
    "\n",
    "# Load and prepare data\n",
    "nodes_csv = \"data/nodes.csv\"  # Replace with your actual path\n",
    "edges_csv = \"data/edges.csv\"  # Replace with your actual path\n",
    "\n",
    "node_types_dict, edge_types_dict, mapping = loader.load_and_prepare_primekg(nodes_csv, edges_csv)\n",
    "\n",
    "    \n",
    "# Get type mappings for reference\n",
    "mappings = loader.get_type_mappings()\n",
    "print(\"\\nType mappings created:\")\n",
    "print(\"Node types:\", mappings['node_types'])\n",
    "print(\"Relationship types:\", mappings['relationship_types'])\n",
    "\n",
    "# Verify data format\n",
    "print(\"\\nData format verification:\")\n",
    "for node_type, df in node_types_dict.items():\n",
    "    print(f\"  {node_type}: node_id range {df['node_id'].min()}-{df['node_id'].max()}\")\n",
    "\n",
    "# Now you can use this data with your DGL graph analyzer\n",
    "print(\"\\nReady to load into DGL!\")\n",
    "print(\"Use: analyzer.bulk_load_heterogeneous_graph(node_types_dict, edge_types_dict)\")\n",
    "db.bulk_load_heterogeneous_graph(node_types_dict, edge_types_dict)\n",
    "db.set_mappings(loader.node_type_mapping, loader.relationship_type_mapping)\n",
    "db.set_global_to_local_mapping(mapping)\n",
    "\n",
    "# x = torch.rand(max(db.global_to_local_mapping.keys())+1, 256)\n",
    "# db.load_node_features_for_gnn(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa7800e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping = dict(sorted(db.global_to_local_mapping.items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3866df8",
   "metadata": {},
   "outputs": [],
   "source": [
    "names = []\n",
    "\n",
    "for key, value in mapping.items():\n",
    "    names.append(db.node_data[value[0]]['name'][value[1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41c2a7c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "model = SentenceTransformer(\"all-mpnet-base-v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7b16b76",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = model.encode(names)\n",
    "\n",
    "torch.save(embeddings, \"/home/cc/PHD/dglframework/DeepKG/DeepGraphDB/start_feats.pt\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
