{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "580f43d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from ChromaVDB.chroma import ChromaFramework\n",
    "from DeepGraphDB import DeepGraphDB\n",
    "from tqdm.notebook import tqdm\n",
    "import torch\n",
    "\n",
    "gdb = DeepGraphDB()\n",
    "gdb.load_graph(\"/home/cc/PHD/dglframework/DeepKG/DeepGraphDB/graphs/primekg.bin\")\n",
    "\n",
    "vdb = ChromaFramework(persist_directory=\"./ChromaVDB/chroma_db\")\n",
    "records = vdb.list_records()\n",
    "\n",
    "names = [record['name'] for record in records]\n",
    "embs = [record['embeddings'] for record in records]\n",
    "ids = [record['id'] for record in records]\n",
    "\n",
    "data = pd.read_excel('data/2025_03_29.xlsx') # Provare ad usare anche stadio-avanzato, IPI e Log10hGE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "913f7636",
   "metadata": {},
   "outputs": [],
   "source": [
    "# gene_set = \"LNF\"\n",
    "gene_set = \"plasma\"\n",
    "# gene_measure = \"MUT\"\n",
    "gene_measure = \"VAF\"\n",
    "\n",
    "gene_data = data[[col for col in data.columns if gene_set in col and gene_measure in col]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efc6e838",
   "metadata": {},
   "outputs": [],
   "source": [
    "genes = list(set([ gene.split('_')[0] for gene in gene_data.columns  ]))\n",
    "\n",
    "final_columns = []\n",
    "embeddings = []\n",
    "record_ids = []\n",
    "\n",
    "for gene in genes:\n",
    "    if gene in names:\n",
    "        final_columns.append(gene+\"_\"+gene_set+\"_\"+gene_measure)\n",
    "        embeddings.append(embs[names.index(gene)])\n",
    "        record_ids.append(ids[names.index(gene)])\n",
    "    else:\n",
    "        print(gene)\n",
    "\n",
    "print(len(final_columns))\n",
    "\n",
    "gene_data = gene_data[final_columns]\n",
    "gene_data['pfs'] = data['PFS_Cens_updated']\n",
    "# gene_data = gene_data.dropna()\n",
    "gene_data = gene_data.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82a2ebe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_patient(vdb, gdb, record_ids, gene_data):\n",
    "    label = int(gene_data['pfs'])\n",
    "    gene_data = gene_data.drop(labels=['pfs'])\n",
    "\n",
    "    inv = dict(zip(vdb.global_to_vids_mapping.values(), vdb.global_to_vids_mapping.keys()))\n",
    "    g_ids = [ inv[id] for id in record_ids ]\n",
    "\n",
    "    ctypes = [ ctype for ctype in  gdb.graph.canonical_etypes if ctype[0] == \"geneprotein\" and ctype[2] == \"geneprotein\" ]\n",
    "\n",
    "    # sb = gdb.extract_subgraph(np.array(g_ids)[gene_data.loc[0].values > 0], 2, max_neighbors_per_hop=[50, 25])\n",
    "    sb = gdb.get_k_hop_neighbors(np.array(g_ids)[gene_data.values > 0], 1, edge_types=ctypes)\n",
    "\n",
    "    flat_ids = np.array([item for sublist in sb.values() for item in sublist])\n",
    "\n",
    "    start_ids = np.setdiff1d(flat_ids, np.array(g_ids)[gene_data.values <= 0])\n",
    "    print(f\"Genes included in graph: {start_ids.shape}\")\n",
    "\n",
    "    ctypes_2 = [ ctype for ctype in  gdb.graph.canonical_etypes if ctype[0] == \"geneprotein\" or ctype[2] == \"geneprotein\" ]\n",
    "    ctypes_2.remove(('geneprotein', 'protein_protein', 'geneprotein'))\n",
    "\n",
    "    sb_2 = gdb.get_k_hop_neighbors(start_ids, 1, edge_types=ctypes_2)\n",
    "    flat_ids_final = np.array([item for sublist in sb_2.values() for item in sublist])\n",
    "    print(f\"Total nodes to embed: {flat_ids_final.shape}\")\n",
    "\n",
    "    return flat_ids_final\n",
    "\n",
    "    # ids_to_search = [ vdb.global_to_vids_mapping[id] for id in flat_ids_final ]\n",
    "    # retrived_records = vdb.read_record(ids_to_search, include_embeddings=True)\n",
    "\n",
    "    # return torch.tensor(np.array([ record['embeddings']['graph'] for record in retrived_records ])).mean(dim=0), label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9e1a837",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_ids = encode_patient(vdb, gdb, record_ids, gene_data.loc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a251c31d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "local_ids = [ gdb.global_to_local_mapping[g_id] for g_id in final_ids ]\n",
    "\n",
    "# Create dictionary with entity names as keys and lists of IDs as values\n",
    "entity_dict = defaultdict(list)\n",
    "\n",
    "for entity_name, entity_id in local_ids:\n",
    "    entity_dict[entity_name].append(entity_id)\n",
    "\n",
    "# Convert to regular dict if needed\n",
    "entity_dict = dict(entity_dict)\n",
    "\n",
    "print(entity_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7035130a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dgl\n",
    "import torch\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "from typing import Dict, List, Tuple, Set\n",
    "        \n",
    "def create_subgraph_from_node_lists(graph, node_lists: Dict[str, List[int]]) -> dgl.DGLGraph:\n",
    "    \"\"\"\n",
    "    Create a subgraph from lists of node IDs for each entity type.\n",
    "    \n",
    "    Args:\n",
    "        node_lists: Dictionary mapping node type to list of node IDs\n",
    "                    e.g., {'user': [0, 1, 5], 'item': [2, 7, 9], 'category': [1, 3]}\n",
    "    \n",
    "    Returns:\n",
    "        DGL heterogeneous subgraph containing only specified nodes and their connections\n",
    "    \"\"\"\n",
    "    # Convert node lists to sets for faster lookup\n",
    "    target_nodes = {ntype: set(nodes) for ntype, nodes in node_lists.items()}\n",
    "    \n",
    "    # Create mapping from old node IDs to new node IDs\n",
    "    old_to_new_mapping = {}\n",
    "    new_node_counts = {}\n",
    "    \n",
    "    for ntype in graph.ntypes:\n",
    "        if ntype in target_nodes:\n",
    "            old_ids = sorted(list(target_nodes[ntype]))\n",
    "            new_ids = list(range(len(old_ids)))\n",
    "            old_to_new_mapping[ntype] = dict(zip(old_ids, new_ids))\n",
    "            new_node_counts[ntype] = len(old_ids)\n",
    "        else:\n",
    "            old_to_new_mapping[ntype] = {}\n",
    "            new_node_counts[ntype] = 0\n",
    "    \n",
    "    # Extract edges for each edge type\n",
    "    subgraph_edges = {}\n",
    "    \n",
    "    for canonical_etype in graph.canonical_etypes:\n",
    "        src_type, etype, dst_type = canonical_etype\n",
    "        \n",
    "        # Skip if either source or destination type has no target nodes\n",
    "        if (src_type not in target_nodes or dst_type not in target_nodes or\n",
    "            len(target_nodes[src_type]) == 0 or len(target_nodes[dst_type]) == 0):\n",
    "            subgraph_edges[canonical_etype] = ([], [])\n",
    "            continue\n",
    "        \n",
    "        # Get all edges of this type from the full graph\n",
    "        src_nodes, dst_nodes = graph.edges(etype=canonical_etype)\n",
    "        src_nodes = src_nodes.numpy()\n",
    "        dst_nodes = dst_nodes.numpy()\n",
    "        \n",
    "        # Filter edges to only include those between target nodes\n",
    "        valid_edges = []\n",
    "        for i, (src, dst) in enumerate(zip(src_nodes, dst_nodes)):\n",
    "            if (src in target_nodes[src_type] and \n",
    "                dst in target_nodes[dst_type]):\n",
    "                # Map to new node IDs\n",
    "                new_src = old_to_new_mapping[src_type][src]\n",
    "                new_dst = old_to_new_mapping[dst_type][dst]\n",
    "                valid_edges.append((new_src, new_dst))\n",
    "        \n",
    "        if valid_edges:\n",
    "            src_list, dst_list = zip(*valid_edges)\n",
    "            subgraph_edges[canonical_etype] = (list(src_list), list(dst_list))\n",
    "        else:\n",
    "            subgraph_edges[canonical_etype] = ([], [])\n",
    "    \n",
    "    # Create the new heterogeneous graph\n",
    "    subgraph = dgl.heterograph(subgraph_edges, num_nodes_dict=new_node_counts)\n",
    "    \n",
    "    # Copy node features if they exist\n",
    "    _copy_node_features(graph, subgraph, old_to_new_mapping, target_nodes)\n",
    "    \n",
    "    # Copy edge features if they exist\n",
    "    _copy_edge_features(graph, subgraph, subgraph_edges, old_to_new_mapping, target_nodes)\n",
    "    \n",
    "    return subgraph\n",
    "\n",
    "def _copy_node_features(graph: dgl.DGLGraph, subgraph: dgl.DGLGraph, \n",
    "                        old_to_new_mapping: Dict[str, Dict[int, int]],\n",
    "                        target_nodes: Dict[str, Set[int]]):\n",
    "    \"\"\"Copy node features from full graph to subgraph.\"\"\"\n",
    "    for ntype in graph.ntypes:\n",
    "        if ntype not in target_nodes or len(target_nodes[ntype]) == 0:\n",
    "            continue\n",
    "            \n",
    "        # Get node features from full graph\n",
    "        node_data = graph.nodes[ntype].data\n",
    "        \n",
    "        for feat_name, feat_tensor in node_data.items():\n",
    "            # Get the old node IDs in the order they appear in the new graph\n",
    "            old_ids = sorted(list(target_nodes[ntype]))\n",
    "            \n",
    "            # Extract features for target nodes\n",
    "            subgraph_features = feat_tensor[old_ids]\n",
    "            \n",
    "            # Set features in subgraph\n",
    "            subgraph.nodes[ntype].data[feat_name] = subgraph_features\n",
    "\n",
    "def _copy_edge_features(graph: dgl.DGLGraph, subgraph: dgl.DGLGraph,\n",
    "                        subgraph_edges: Dict[Tuple[str, str, str], Tuple[List[int], List[int]]],\n",
    "                        old_to_new_mapping: Dict[str, Dict[int, int]],\n",
    "                        target_nodes: Dict[str, Set[int]]):\n",
    "    \"\"\"Copy edge features from full graph to subgraph.\"\"\"\n",
    "    for canonical_etype in graph.canonical_etypes:\n",
    "        src_type, etype, dst_type = canonical_etype\n",
    "        \n",
    "        # Skip if no edges of this type in subgraph\n",
    "        if len(subgraph_edges[canonical_etype][0]) == 0:\n",
    "            continue\n",
    "        \n",
    "        # Get edge data from full graph\n",
    "        edge_data = graph.edges[canonical_etype].data\n",
    "        \n",
    "        if not edge_data:\n",
    "            continue\n",
    "        \n",
    "        # Get original edges\n",
    "        orig_src, orig_dst = graph.edges(etype=canonical_etype)\n",
    "        orig_src = orig_src.numpy()\n",
    "        orig_dst = orig_dst.numpy()\n",
    "        \n",
    "        # Find indices of edges that are in the subgraph\n",
    "        edge_indices = []\n",
    "        for i, (src, dst) in enumerate(zip(orig_src, orig_dst)):\n",
    "            if (src in target_nodes[src_type] and \n",
    "                dst in target_nodes[dst_type]):\n",
    "                edge_indices.append(i)\n",
    "        \n",
    "        # Copy edge features\n",
    "        for feat_name, feat_tensor in edge_data.items():\n",
    "            if edge_indices:\n",
    "                subgraph_features = feat_tensor[edge_indices]\n",
    "                subgraph.edges[canonical_etype].data[feat_name] = subgraph_features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c74c159e",
   "metadata": {},
   "outputs": [],
   "source": [
    "subgraph = create_subgraph_from_node_lists(gdb.graph, entity_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9a2e9df",
   "metadata": {},
   "outputs": [],
   "source": [
    "from DeepGraphDB.gnns.patientTuning import PatientSpecificFineTuner\n",
    "\n",
    "ctypes = [ ctype for ctype in subgraph.canonical_etypes if ctype[0] == \"geneprotein\" or ctype[1] == \"geneprotein\"]\n",
    "\n",
    "node_types = subgraph.ntypes\n",
    "edge_types = ctypes\n",
    "target_etypes = ctypes\n",
    "\n",
    "# Initialize fine-tuner with pretrained model\n",
    "fine_tuner = PatientSpecificFineTuner(\n",
    "    base_model_path='model.pt',\n",
    "    node_types=node_types,\n",
    "    edge_types=edge_types,\n",
    "    device='cuda' if torch.cuda.is_available() else 'cpu'\n",
    ")\n",
    "\n",
    "# Example patient data (you would load your actual patient subgraphs)\n",
    "patient_graphs = {\n",
    "    'patient_1': subgraph\n",
    "}\n",
    "\n",
    "# Fine-tune models for all patients\n",
    "results = fine_tuner.batch_fine_tune_patients(\n",
    "    patient_data_dict=patient_graphs,\n",
    "    target_etypes=target_etypes,\n",
    "    save_dir='/home/cc/PHD/dglframework/DeepKG/embeddings/patient_specific_models'\n",
    ")\n",
    "\n",
    "# Print results\n",
    "for patient_id, result in results.items():\n",
    "    print(f\"Patient {patient_id}: AUC = {result['best_auc']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "659aa0e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "patient_embs = []\n",
    "labels = []\n",
    "\n",
    "for i, row in tqdm(gene_data.iterrows()):\n",
    "    print(f\"--- Patient {i} ---\")\n",
    "    p_emb, label = encode_patient(vdb, gdb, record_ids, gene_data.loc[i])\n",
    "    \n",
    "    if not torch.any(p_emb.isnan()):\n",
    "        patient_embs.append(p_emb)\n",
    "        labels.append(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "727de1df",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.decomposition import PCA\n",
    "import torch\n",
    "\n",
    "def visualize_embeddings_tsne(embeddings, labels, perplexity=30, n_iter=1000, random_state=42):\n",
    "    \"\"\"\n",
    "    Visualize tensor embeddings using t-SNE with binary labels\n",
    "    \n",
    "    Args:\n",
    "        embeddings: List of tensors or numpy arrays, or a single tensor/array\n",
    "        labels: List of binary labels (0s and 1s)\n",
    "        perplexity: t-SNE perplexity parameter (default: 30)\n",
    "        n_iter: Number of iterations for t-SNE (default: 1000)\n",
    "        random_state: Random state for reproducibility (default: 42)\n",
    "    \"\"\"\n",
    "    \n",
    "    # Convert tensors to numpy if needed\n",
    "    if isinstance(embeddings, list):\n",
    "        if torch.is_tensor(embeddings[0]):\n",
    "            # Convert list of tensors to numpy array\n",
    "            embs_np = torch.stack(embeddings).detach().cpu().numpy()\n",
    "        else:\n",
    "            # Assume list of numpy arrays\n",
    "            embs_np = np.array(embeddings)\n",
    "    elif torch.is_tensor(embeddings):\n",
    "        # Single tensor\n",
    "        embs_np = embeddings.detach().cpu().numpy()\n",
    "    else:\n",
    "        # Assume numpy array\n",
    "        embs_np = embeddings\n",
    "    \n",
    "    # Reshape if needed (flatten each embedding)\n",
    "    if len(embs_np.shape) > 2:\n",
    "        embs_np = embs_np.reshape(embs_np.shape[0], -1)\n",
    "    \n",
    "    # Convert labels to numpy array\n",
    "    labels_np = np.array(labels)\n",
    "    \n",
    "    print(f\"Embedding shape: {embs_np.shape}\")\n",
    "    print(f\"Labels shape: {labels_np.shape}\")\n",
    "    print(f\"Unique labels: {np.unique(labels_np)}\")\n",
    "    \n",
    "    # Apply t-SNE\n",
    "    print(\"Applying t-SNE...\")\n",
    "    tsne = TSNE(n_components=2, init='pca', perplexity=perplexity, n_iter=n_iter, random_state=random_state)\n",
    "    # tsne = PCA(n_components=2)\n",
    "    embeddings_2d = tsne.fit_transform(embs_np)\n",
    "    \n",
    "    # Create the plot\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    \n",
    "    # Plot points with different colors for different labels\n",
    "    colors = ['red', 'blue']\n",
    "    labels_text = ['Label 0', 'Label 1']\n",
    "    \n",
    "    for i, label in enumerate([0, 1]):\n",
    "        mask = labels_np == label\n",
    "        if np.any(mask):  # Only plot if this label exists\n",
    "            plt.scatter(embeddings_2d[mask, 0], embeddings_2d[mask, 1], \n",
    "                       c=colors[i], label=labels_text[i], alpha=0.7, s=50)\n",
    "    \n",
    "    plt.title('t-SNE Visualization of Embeddings', fontsize=16)\n",
    "    plt.xlabel('t-SNE Component 1', fontsize=12)\n",
    "    plt.ylabel('t-SNE Component 2', fontsize=12)\n",
    "    plt.legend()\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # Show the plot\n",
    "    plt.show()\n",
    "    \n",
    "    return embeddings_2d, tsne"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f309639f",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_2d, tsne_model = visualize_embeddings_tsne(patient_embs, labels, perplexity=25)\n",
    "\n",
    "print(f\"Final 2D embeddings shape: {embeddings_2d.shape}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
